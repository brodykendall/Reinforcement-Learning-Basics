{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have properly installed pytorch: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9b3019e4f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard code to check device.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Making sure we get the same results every time.\n",
    "torch.manual_seed(922)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], [9.779], [6.182], [7.59], [2.167], [7.042], [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], [3.366], [2.596], [2.53], [1.221], [2.827], [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch uses the nn.Module object to define neural networks. These models need to 1) subclass nn.Module, 2) have an init function that calls super. This function is also where you define the neural network layers. 3) A forward function that you will call to actually run data through. It usually has as input a variable called 'x' or similar, that is an array of input data we will use to make predictions. See below for an example of an nn.Module class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(input_size, hidden_size=4, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 38.9800\n",
      "Epoch [10/100], Loss: 15.9871\n",
      "Epoch [15/100], Loss: 6.6720\n",
      "Epoch [20/100], Loss: 2.8981\n",
      "Epoch [25/100], Loss: 1.3690\n",
      "Epoch [30/100], Loss: 0.7493\n",
      "Epoch [35/100], Loss: 0.4980\n",
      "Epoch [40/100], Loss: 0.3959\n",
      "Epoch [45/100], Loss: 0.3543\n",
      "Epoch [50/100], Loss: 0.3372\n",
      "Epoch [55/100], Loss: 0.3301\n",
      "Epoch [60/100], Loss: 0.3269\n",
      "Epoch [65/100], Loss: 0.3254\n",
      "Epoch [70/100], Loss: 0.3246\n",
      "Epoch [75/100], Loss: 0.3240\n",
      "Epoch [80/100], Loss: 0.3235\n",
      "Epoch [85/100], Loss: 0.3231\n",
      "Epoch [90/100], Loss: 0.3227\n",
      "Epoch [95/100], Loss: 0.3223\n",
      "Epoch [100/100], Loss: 0.3219\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1 Use a neural network.\n",
    "Rather than the linear model the code is currently using, use a neural network model. A basic neural network is already defined for you in the code, so all you need to do is call model = NeuralNet(...). You should use a hidden size of 4.\n",
    "\n",
    "What is the training loss of the neural network model? How does it compare? Plot the predicted output of the neural network.\n",
    "\n",
    "Hint: nets are non-linear, so you need to change plt.plot(x_train, predicted, label='Fitted line') to plt.plot(x_train, predicted, 'bo', label='Fitted line') since you are no longer predicting a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size=4, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 6.0836\n",
      "Epoch [10/100], Loss: 2.7438\n",
      "Epoch [15/100], Loss: 1.2737\n",
      "Epoch [20/100], Loss: 0.6279\n",
      "Epoch [25/100], Loss: 0.3546\n",
      "Epoch [30/100], Loss: 0.2435\n",
      "Epoch [35/100], Loss: 0.1997\n",
      "Epoch [40/100], Loss: 0.1828\n",
      "Epoch [45/100], Loss: 0.1764\n",
      "Epoch [50/100], Loss: 0.1740\n",
      "Epoch [55/100], Loss: 0.1731\n",
      "Epoch [60/100], Loss: 0.1727\n",
      "Epoch [65/100], Loss: 0.1726\n",
      "Epoch [70/100], Loss: 0.1725\n",
      "Epoch [75/100], Loss: 0.1725\n",
      "Epoch [80/100], Loss: 0.1725\n",
      "Epoch [85/100], Loss: 0.1724\n",
      "Epoch [90/100], Loss: 0.1724\n",
      "Epoch [95/100], Loss: 0.1724\n",
      "Epoch [100/100], Loss: 0.1724\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, 'bo', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loss of the neural network model is 0.1724, which is smaller than that of the linear model (0.3219)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2 Change the network activation to Tanh.\n",
    "\n",
    "Plot the results and compare them to using an activation function of RelU. What advantages does RelU have for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNetTan(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_dim):\n",
    "        super(NeuralNetTan, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_size, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetTan(input_size, hidden_size=4, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 8.7117\n",
      "Epoch [10/100], Loss: 8.0073\n",
      "Epoch [15/100], Loss: 7.3643\n",
      "Epoch [20/100], Loss: 6.7772\n",
      "Epoch [25/100], Loss: 6.2412\n",
      "Epoch [30/100], Loss: 5.7517\n",
      "Epoch [35/100], Loss: 5.3047\n",
      "Epoch [40/100], Loss: 4.8965\n",
      "Epoch [45/100], Loss: 4.5236\n",
      "Epoch [50/100], Loss: 4.1829\n",
      "Epoch [55/100], Loss: 3.8715\n",
      "Epoch [60/100], Loss: 3.5869\n",
      "Epoch [65/100], Loss: 3.3266\n",
      "Epoch [70/100], Loss: 3.0885\n",
      "Epoch [75/100], Loss: 2.8707\n",
      "Epoch [80/100], Loss: 2.6713\n",
      "Epoch [85/100], Loss: 2.4886\n",
      "Epoch [90/100], Loss: 2.3213\n",
      "Epoch [95/100], Loss: 2.1680\n",
      "Epoch [100/100], Loss: 2.0274\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, 'bo', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3 Change the number of hidden units.\n",
    "\n",
    "Change the hidden units in the network from 4 to 16. How does this impact the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetTan(input_size, hidden_size=16, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 3.3517\n",
      "Epoch [10/100], Loss: 2.5640\n",
      "Epoch [15/100], Loss: 1.9869\n",
      "Epoch [20/100], Loss: 1.5643\n",
      "Epoch [25/100], Loss: 1.2547\n",
      "Epoch [30/100], Loss: 1.0280\n",
      "Epoch [35/100], Loss: 0.8619\n",
      "Epoch [40/100], Loss: 0.7403\n",
      "Epoch [45/100], Loss: 0.6511\n",
      "Epoch [50/100], Loss: 0.5858\n",
      "Epoch [55/100], Loss: 0.5378\n",
      "Epoch [60/100], Loss: 0.5025\n",
      "Epoch [65/100], Loss: 0.4766\n",
      "Epoch [70/100], Loss: 0.4574\n",
      "Epoch [75/100], Loss: 0.4432\n",
      "Epoch [80/100], Loss: 0.4327\n",
      "Epoch [85/100], Loss: 0.4248\n",
      "Epoch [90/100], Loss: 0.4189\n",
      "Epoch [95/100], Loss: 0.4144\n",
      "Epoch [100/100], Loss: 0.4109\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, 'bo', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #4 Change the learning rate.\n",
    "\n",
    "Change the learning rate to 0.01. How does this impact the results? What happens if the learning rate is set to 0.1 instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetTan(input_size, hidden_size=16, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.8932\n",
      "Epoch [10/100], Loss: 0.4654\n",
      "Epoch [15/100], Loss: 0.4466\n",
      "Epoch [20/100], Loss: 0.4396\n",
      "Epoch [25/100], Loss: 0.4331\n",
      "Epoch [30/100], Loss: 0.4267\n",
      "Epoch [35/100], Loss: 0.4203\n",
      "Epoch [40/100], Loss: 0.4140\n",
      "Epoch [45/100], Loss: 0.4077\n",
      "Epoch [50/100], Loss: 0.4015\n",
      "Epoch [55/100], Loss: 0.3952\n",
      "Epoch [60/100], Loss: 0.3889\n",
      "Epoch [65/100], Loss: 0.3826\n",
      "Epoch [70/100], Loss: 0.3762\n",
      "Epoch [75/100], Loss: 0.3697\n",
      "Epoch [80/100], Loss: 0.3632\n",
      "Epoch [85/100], Loss: 0.3566\n",
      "Epoch [90/100], Loss: 0.3499\n",
      "Epoch [95/100], Loss: 0.3431\n",
      "Epoch [100/100], Loss: 0.3362\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, 'bo', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #5 Add momentum to the optimizer.\n",
    "\n",
    "SGD takes an optional momentum argument. Add a momentum of 0.6 to the optimizer. Does this change the results at all? What does the rate of convergence look like compared to normal SGD without momentum? How many iterations does each option take to converge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size=16, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.2436\n",
      "Epoch [10/100], Loss: 0.2324\n",
      "Epoch [15/100], Loss: 0.1839\n",
      "Epoch [20/100], Loss: 0.1803\n",
      "Epoch [25/100], Loss: 0.1775\n",
      "Epoch [30/100], Loss: 0.1755\n",
      "Epoch [35/100], Loss: 0.1739\n",
      "Epoch [40/100], Loss: 0.1728\n",
      "Epoch [45/100], Loss: 0.1718\n",
      "Epoch [50/100], Loss: 0.1711\n",
      "Epoch [55/100], Loss: 0.1706\n",
      "Epoch [60/100], Loss: 0.1701\n",
      "Epoch [65/100], Loss: 0.1698\n",
      "Epoch [70/100], Loss: 0.1695\n",
      "Epoch [75/100], Loss: 0.1693\n",
      "Epoch [80/100], Loss: 0.1692\n",
      "Epoch [85/100], Loss: 0.1691\n",
      "Epoch [90/100], Loss: 0.1690\n",
      "Epoch [95/100], Loss: 0.1689\n",
      "Epoch [100/100], Loss: 0.1688\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, 'bo', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #6 Increase the training time.\n",
    "\n",
    "Increase the number of training iterations by x10, to 600. What happens to the loss over time? How should we decide when to stop training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetTan(input_size, hidden_size=16, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/600], Loss: 0.6946\n",
      "Epoch [10/600], Loss: 0.4598\n",
      "Epoch [15/600], Loss: 0.4393\n",
      "Epoch [20/600], Loss: 0.4248\n",
      "Epoch [25/600], Loss: 0.4096\n",
      "Epoch [30/600], Loss: 0.3937\n",
      "Epoch [35/600], Loss: 0.3771\n",
      "Epoch [40/600], Loss: 0.3595\n",
      "Epoch [45/600], Loss: 0.3408\n",
      "Epoch [50/600], Loss: 0.3213\n",
      "Epoch [55/600], Loss: 0.3020\n",
      "Epoch [60/600], Loss: 0.2845\n",
      "Epoch [65/600], Loss: 0.2702\n",
      "Epoch [70/600], Loss: 0.2588\n",
      "Epoch [75/600], Loss: 0.2493\n",
      "Epoch [80/600], Loss: 0.2410\n",
      "Epoch [85/600], Loss: 0.2335\n",
      "Epoch [90/600], Loss: 0.2267\n",
      "Epoch [95/600], Loss: 0.2205\n",
      "Epoch [100/600], Loss: 0.2150\n",
      "Epoch [105/600], Loss: 0.2101\n",
      "Epoch [110/600], Loss: 0.2057\n",
      "Epoch [115/600], Loss: 0.2018\n",
      "Epoch [120/600], Loss: 0.1984\n",
      "Epoch [125/600], Loss: 0.1954\n",
      "Epoch [130/600], Loss: 0.1927\n",
      "Epoch [135/600], Loss: 0.1905\n",
      "Epoch [140/600], Loss: 0.1885\n",
      "Epoch [145/600], Loss: 0.1868\n",
      "Epoch [150/600], Loss: 0.1852\n",
      "Epoch [155/600], Loss: 0.1839\n",
      "Epoch [160/600], Loss: 0.1828\n",
      "Epoch [165/600], Loss: 0.1818\n",
      "Epoch [170/600], Loss: 0.1809\n",
      "Epoch [175/600], Loss: 0.1800\n",
      "Epoch [180/600], Loss: 0.1793\n",
      "Epoch [185/600], Loss: 0.1787\n",
      "Epoch [190/600], Loss: 0.1781\n",
      "Epoch [195/600], Loss: 0.1775\n",
      "Epoch [200/600], Loss: 0.1770\n",
      "Epoch [205/600], Loss: 0.1766\n",
      "Epoch [210/600], Loss: 0.1761\n",
      "Epoch [215/600], Loss: 0.1757\n",
      "Epoch [220/600], Loss: 0.1753\n",
      "Epoch [225/600], Loss: 0.1750\n",
      "Epoch [230/600], Loss: 0.1746\n",
      "Epoch [235/600], Loss: 0.1743\n",
      "Epoch [240/600], Loss: 0.1740\n",
      "Epoch [245/600], Loss: 0.1737\n",
      "Epoch [250/600], Loss: 0.1734\n",
      "Epoch [255/600], Loss: 0.1731\n",
      "Epoch [260/600], Loss: 0.1729\n",
      "Epoch [265/600], Loss: 0.1726\n",
      "Epoch [270/600], Loss: 0.1724\n",
      "Epoch [275/600], Loss: 0.1721\n",
      "Epoch [280/600], Loss: 0.1719\n",
      "Epoch [285/600], Loss: 0.1717\n",
      "Epoch [290/600], Loss: 0.1715\n",
      "Epoch [295/600], Loss: 0.1713\n",
      "Epoch [300/600], Loss: 0.1711\n",
      "Epoch [305/600], Loss: 0.1710\n",
      "Epoch [310/600], Loss: 0.1708\n",
      "Epoch [315/600], Loss: 0.1707\n",
      "Epoch [320/600], Loss: 0.1705\n",
      "Epoch [325/600], Loss: 0.1704\n",
      "Epoch [330/600], Loss: 0.1703\n",
      "Epoch [335/600], Loss: 0.1702\n",
      "Epoch [340/600], Loss: 0.1701\n",
      "Epoch [345/600], Loss: 0.1700\n",
      "Epoch [350/600], Loss: 0.1699\n",
      "Epoch [355/600], Loss: 0.1698\n",
      "Epoch [360/600], Loss: 0.1697\n",
      "Epoch [365/600], Loss: 0.1697\n",
      "Epoch [370/600], Loss: 0.1696\n",
      "Epoch [375/600], Loss: 0.1695\n",
      "Epoch [380/600], Loss: 0.1695\n",
      "Epoch [385/600], Loss: 0.1694\n",
      "Epoch [390/600], Loss: 0.1694\n",
      "Epoch [395/600], Loss: 0.1693\n",
      "Epoch [400/600], Loss: 0.1693\n",
      "Epoch [405/600], Loss: 0.1693\n",
      "Epoch [410/600], Loss: 0.1692\n",
      "Epoch [415/600], Loss: 0.1692\n",
      "Epoch [420/600], Loss: 0.1691\n",
      "Epoch [425/600], Loss: 0.1691\n",
      "Epoch [430/600], Loss: 0.1691\n",
      "Epoch [435/600], Loss: 0.1691\n",
      "Epoch [440/600], Loss: 0.1690\n",
      "Epoch [445/600], Loss: 0.1690\n",
      "Epoch [450/600], Loss: 0.1690\n",
      "Epoch [455/600], Loss: 0.1689\n",
      "Epoch [460/600], Loss: 0.1689\n",
      "Epoch [465/600], Loss: 0.1689\n",
      "Epoch [470/600], Loss: 0.1689\n",
      "Epoch [475/600], Loss: 0.1688\n",
      "Epoch [480/600], Loss: 0.1688\n",
      "Epoch [485/600], Loss: 0.1688\n",
      "Epoch [490/600], Loss: 0.1688\n",
      "Epoch [495/600], Loss: 0.1688\n",
      "Epoch [500/600], Loss: 0.1687\n",
      "Epoch [505/600], Loss: 0.1687\n",
      "Epoch [510/600], Loss: 0.1687\n",
      "Epoch [515/600], Loss: 0.1687\n",
      "Epoch [520/600], Loss: 0.1687\n",
      "Epoch [525/600], Loss: 0.1686\n",
      "Epoch [530/600], Loss: 0.1686\n",
      "Epoch [535/600], Loss: 0.1686\n",
      "Epoch [540/600], Loss: 0.1686\n",
      "Epoch [545/600], Loss: 0.1686\n",
      "Epoch [550/600], Loss: 0.1686\n",
      "Epoch [555/600], Loss: 0.1685\n",
      "Epoch [560/600], Loss: 0.1685\n",
      "Epoch [565/600], Loss: 0.1685\n",
      "Epoch [570/600], Loss: 0.1685\n",
      "Epoch [575/600], Loss: 0.1685\n",
      "Epoch [580/600], Loss: 0.1685\n",
      "Epoch [585/600], Loss: 0.1685\n",
      "Epoch [590/600], Loss: 0.1684\n",
      "Epoch [595/600], Loss: 0.1684\n",
      "Epoch [600/600], Loss: 0.1684\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, 'bo', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #7 Nonelinear data\n",
    "\n",
    "Change y_train to instead be x^2.\n",
    "\n",
    "Train a neural net model on this data for 100 epochs, using RELU activation, momentum = 0.6, 16 hidden units, and learning rate 0.001.\n",
    "\n",
    "Compare your results to a linear model trained to predict y=x^2, plotting both. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.square(x_train)\n",
    "num_epochs = 100\n",
    "momentum = 0.6\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = NeuralNet(input_size, hidden_size=16, out_dim=1).to(device)\n",
    "model_linear = LinearModel(input_size, hidden_size=16, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion_nn = nn.MSELoss()\n",
    "optimizer_nn = torch.optim.SGD(model_nn.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# Loss and optimizer\n",
    "criterion_linear = nn.MSELoss()\n",
    "optimizer_linear = torch.optim.SGD(model_linear.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 281.8204\n",
      "Epoch [10/100], Loss: 251.7977\n",
      "Epoch [15/100], Loss: 208.9558\n",
      "Epoch [20/100], Loss: 192.0236\n",
      "Epoch [25/100], Loss: 177.6155\n",
      "Epoch [30/100], Loss: 163.7902\n",
      "Epoch [35/100], Loss: 150.3571\n",
      "Epoch [40/100], Loss: 137.1929\n",
      "Epoch [45/100], Loss: 124.2935\n",
      "Epoch [50/100], Loss: 111.7513\n",
      "Epoch [55/100], Loss: 99.7367\n",
      "Epoch [60/100], Loss: 88.4688\n",
      "Epoch [65/100], Loss: 78.1820\n",
      "Epoch [70/100], Loss: 69.0223\n",
      "Epoch [75/100], Loss: 61.0907\n",
      "Epoch [80/100], Loss: 54.2519\n",
      "Epoch [85/100], Loss: 48.3656\n",
      "Epoch [90/100], Loss: 43.3896\n",
      "Epoch [95/100], Loss: 39.1147\n",
      "Epoch [100/100], Loss: 35.3205\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model_nn(inputs)\n",
    "    loss = criterion_nn(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer_nn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_nn.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 753.5104\n",
      "Epoch [10/100], Loss: 218.2287\n",
      "Epoch [15/100], Loss: 212.0596\n",
      "Epoch [20/100], Loss: 209.9234\n",
      "Epoch [25/100], Loss: 208.5916\n",
      "Epoch [30/100], Loss: 207.5122\n",
      "Epoch [35/100], Loss: 206.4403\n",
      "Epoch [40/100], Loss: 205.3757\n",
      "Epoch [45/100], Loss: 204.3182\n",
      "Epoch [50/100], Loss: 203.2673\n",
      "Epoch [55/100], Loss: 202.2233\n",
      "Epoch [60/100], Loss: 201.1859\n",
      "Epoch [65/100], Loss: 200.1551\n",
      "Epoch [70/100], Loss: 199.1310\n",
      "Epoch [75/100], Loss: 198.1134\n",
      "Epoch [80/100], Loss: 197.1023\n",
      "Epoch [85/100], Loss: 196.0977\n",
      "Epoch [90/100], Loss: 195.0996\n",
      "Epoch [95/100], Loss: 194.1079\n",
      "Epoch [100/100], Loss: 193.1224\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model_linear(inputs)\n",
    "    loss = criterion_linear(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer_linear.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_linear.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted_nn = model_nn(torch.from_numpy(x_train)).detach().numpy()\n",
    "predicted_linear = model_linear(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted_nn, 'bo', label='Fitted line, Neural Net')\n",
    "plt.plot(x_train, predicted_linear, label='Fitted line, Linear Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #8 The best we can do\n",
    "\n",
    "Using the data from question 7 where y=x^2, try to achieve the best possible performance (lowest loss, fastest convergence). Spend a few minutes trying different combinations of:\n",
    "\n",
    "Learning rate\n",
    "Training epochs\n",
    "Hidden Size\n",
    "Number of neural net layers\n",
    "Optimizer choice\n",
    "\n",
    "Report the smallest loss you can get, and what parameters you used to achieve this loss. Do not more than 46 minutes on this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 6000\n",
    "momentum = 0.9\n",
    "hs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = NeuralNet(input_size, hidden_size=hs, out_dim=1).to(device)\n",
    "model_tanh = NeuralNetTan(input_size, hidden_size=hs, out_dim=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion_relu = nn.MSELoss()\n",
    "optimizer_relu = torch.optim.SGD(model_relu.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# Loss and optimizer\n",
    "criterion_tanh = nn.MSELoss()\n",
    "optimizer_tanh = torch.optim.SGD(model_tanh.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/6000], Loss: 1833.2872\n",
      "Epoch [10/6000], Loss: 966.3445\n",
      "Epoch [15/6000], Loss: 238.1414\n",
      "Epoch [20/6000], Loss: 143.7433\n",
      "Epoch [25/6000], Loss: 114.2307\n",
      "Epoch [30/6000], Loss: 215.0695\n",
      "Epoch [35/6000], Loss: 83.6721\n",
      "Epoch [40/6000], Loss: 49.1075\n",
      "Epoch [45/6000], Loss: 32.7090\n",
      "Epoch [50/6000], Loss: 31.4911\n",
      "Epoch [55/6000], Loss: 26.6468\n",
      "Epoch [60/6000], Loss: 23.6332\n",
      "Epoch [65/6000], Loss: 21.7126\n",
      "Epoch [70/6000], Loss: 13.5249\n",
      "Epoch [75/6000], Loss: 10.0660\n",
      "Epoch [80/6000], Loss: 6.6901\n",
      "Epoch [85/6000], Loss: 5.6370\n",
      "Epoch [90/6000], Loss: 4.1946\n",
      "Epoch [95/6000], Loss: 3.1780\n",
      "Epoch [100/6000], Loss: 2.1325\n",
      "Epoch [105/6000], Loss: 1.5389\n",
      "Epoch [110/6000], Loss: 1.2269\n",
      "Epoch [115/6000], Loss: 1.0002\n",
      "Epoch [120/6000], Loss: 0.8438\n",
      "Epoch [125/6000], Loss: 0.7236\n",
      "Epoch [130/6000], Loss: 0.6412\n",
      "Epoch [135/6000], Loss: 0.5709\n",
      "Epoch [140/6000], Loss: 0.5160\n",
      "Epoch [145/6000], Loss: 0.4817\n",
      "Epoch [150/6000], Loss: 0.4542\n",
      "Epoch [155/6000], Loss: 0.4264\n",
      "Epoch [160/6000], Loss: 0.4054\n",
      "Epoch [165/6000], Loss: 0.3881\n",
      "Epoch [170/6000], Loss: 0.3746\n",
      "Epoch [175/6000], Loss: 0.3616\n",
      "Epoch [180/6000], Loss: 0.3497\n",
      "Epoch [185/6000], Loss: 0.3404\n",
      "Epoch [190/6000], Loss: 0.3322\n",
      "Epoch [195/6000], Loss: 0.3213\n",
      "Epoch [200/6000], Loss: 0.3124\n",
      "Epoch [205/6000], Loss: 0.3049\n",
      "Epoch [210/6000], Loss: 0.2975\n",
      "Epoch [215/6000], Loss: 0.2904\n",
      "Epoch [220/6000], Loss: 0.2842\n",
      "Epoch [225/6000], Loss: 0.2783\n",
      "Epoch [230/6000], Loss: 0.2728\n",
      "Epoch [235/6000], Loss: 0.2677\n",
      "Epoch [240/6000], Loss: 0.2629\n",
      "Epoch [245/6000], Loss: 0.2585\n",
      "Epoch [250/6000], Loss: 0.2543\n",
      "Epoch [255/6000], Loss: 0.2504\n",
      "Epoch [260/6000], Loss: 0.2467\n",
      "Epoch [265/6000], Loss: 0.2432\n",
      "Epoch [270/6000], Loss: 0.2400\n",
      "Epoch [275/6000], Loss: 0.2368\n",
      "Epoch [280/6000], Loss: 0.2339\n",
      "Epoch [285/6000], Loss: 0.2312\n",
      "Epoch [290/6000], Loss: 0.2286\n",
      "Epoch [295/6000], Loss: 0.2264\n",
      "Epoch [300/6000], Loss: 0.2240\n",
      "Epoch [305/6000], Loss: 0.2216\n",
      "Epoch [310/6000], Loss: 0.2194\n",
      "Epoch [315/6000], Loss: 0.2172\n",
      "Epoch [320/6000], Loss: 0.2151\n",
      "Epoch [325/6000], Loss: 0.2130\n",
      "Epoch [330/6000], Loss: 0.2110\n",
      "Epoch [335/6000], Loss: 0.2089\n",
      "Epoch [340/6000], Loss: 0.2069\n",
      "Epoch [345/6000], Loss: 0.2049\n",
      "Epoch [350/6000], Loss: 0.2029\n",
      "Epoch [355/6000], Loss: 0.2010\n",
      "Epoch [360/6000], Loss: 0.1991\n",
      "Epoch [365/6000], Loss: 0.1972\n",
      "Epoch [370/6000], Loss: 0.1953\n",
      "Epoch [375/6000], Loss: 0.1935\n",
      "Epoch [380/6000], Loss: 0.1917\n",
      "Epoch [385/6000], Loss: 0.1899\n",
      "Epoch [390/6000], Loss: 0.1881\n",
      "Epoch [395/6000], Loss: 0.1864\n",
      "Epoch [400/6000], Loss: 0.1846\n",
      "Epoch [405/6000], Loss: 0.1829\n",
      "Epoch [410/6000], Loss: 0.1812\n",
      "Epoch [415/6000], Loss: 0.1796\n",
      "Epoch [420/6000], Loss: 0.1779\n",
      "Epoch [425/6000], Loss: 0.1763\n",
      "Epoch [430/6000], Loss: 0.1747\n",
      "Epoch [435/6000], Loss: 0.1731\n",
      "Epoch [440/6000], Loss: 0.1715\n",
      "Epoch [445/6000], Loss: 0.1700\n",
      "Epoch [450/6000], Loss: 0.1684\n",
      "Epoch [455/6000], Loss: 0.1669\n",
      "Epoch [460/6000], Loss: 0.1654\n",
      "Epoch [465/6000], Loss: 0.1639\n",
      "Epoch [470/6000], Loss: 0.1624\n",
      "Epoch [475/6000], Loss: 0.1610\n",
      "Epoch [480/6000], Loss: 0.1596\n",
      "Epoch [485/6000], Loss: 0.1581\n",
      "Epoch [490/6000], Loss: 0.1567\n",
      "Epoch [495/6000], Loss: 0.1554\n",
      "Epoch [500/6000], Loss: 0.1540\n",
      "Epoch [505/6000], Loss: 0.1526\n",
      "Epoch [510/6000], Loss: 0.1513\n",
      "Epoch [515/6000], Loss: 0.1500\n",
      "Epoch [520/6000], Loss: 0.1487\n",
      "Epoch [525/6000], Loss: 0.1474\n",
      "Epoch [530/6000], Loss: 0.1461\n",
      "Epoch [535/6000], Loss: 0.1448\n",
      "Epoch [540/6000], Loss: 0.1436\n",
      "Epoch [545/6000], Loss: 0.1423\n",
      "Epoch [550/6000], Loss: 0.1411\n",
      "Epoch [555/6000], Loss: 0.1399\n",
      "Epoch [560/6000], Loss: 0.1387\n",
      "Epoch [565/6000], Loss: 0.1375\n",
      "Epoch [570/6000], Loss: 0.1363\n",
      "Epoch [575/6000], Loss: 0.1352\n",
      "Epoch [580/6000], Loss: 0.1340\n",
      "Epoch [585/6000], Loss: 0.1329\n",
      "Epoch [590/6000], Loss: 0.1318\n",
      "Epoch [595/6000], Loss: 0.1307\n",
      "Epoch [600/6000], Loss: 0.1296\n",
      "Epoch [605/6000], Loss: 0.1285\n",
      "Epoch [610/6000], Loss: 0.1274\n",
      "Epoch [615/6000], Loss: 0.1263\n",
      "Epoch [620/6000], Loss: 0.1253\n",
      "Epoch [625/6000], Loss: 0.1243\n",
      "Epoch [630/6000], Loss: 0.1232\n",
      "Epoch [635/6000], Loss: 0.1222\n",
      "Epoch [640/6000], Loss: 0.1212\n",
      "Epoch [645/6000], Loss: 0.1202\n",
      "Epoch [650/6000], Loss: 0.1192\n",
      "Epoch [655/6000], Loss: 0.1183\n",
      "Epoch [660/6000], Loss: 0.1173\n",
      "Epoch [665/6000], Loss: 0.1164\n",
      "Epoch [670/6000], Loss: 0.1154\n",
      "Epoch [675/6000], Loss: 0.1145\n",
      "Epoch [680/6000], Loss: 0.1136\n",
      "Epoch [685/6000], Loss: 0.1127\n",
      "Epoch [690/6000], Loss: 0.1118\n",
      "Epoch [695/6000], Loss: 0.1109\n",
      "Epoch [700/6000], Loss: 0.1100\n",
      "Epoch [705/6000], Loss: 0.1091\n",
      "Epoch [710/6000], Loss: 0.1083\n",
      "Epoch [715/6000], Loss: 0.1074\n",
      "Epoch [720/6000], Loss: 0.1056\n",
      "Epoch [725/6000], Loss: 0.1042\n",
      "Epoch [730/6000], Loss: 0.1035\n",
      "Epoch [735/6000], Loss: 0.1023\n",
      "Epoch [740/6000], Loss: 0.1013\n",
      "Epoch [745/6000], Loss: 0.1004\n",
      "Epoch [750/6000], Loss: 0.0994\n",
      "Epoch [755/6000], Loss: 0.0985\n",
      "Epoch [760/6000], Loss: 0.0976\n",
      "Epoch [765/6000], Loss: 0.0967\n",
      "Epoch [770/6000], Loss: 0.0958\n",
      "Epoch [775/6000], Loss: 0.0950\n",
      "Epoch [780/6000], Loss: 0.0941\n",
      "Epoch [785/6000], Loss: 0.0933\n",
      "Epoch [790/6000], Loss: 0.0924\n",
      "Epoch [795/6000], Loss: 0.0916\n",
      "Epoch [800/6000], Loss: 0.0908\n",
      "Epoch [805/6000], Loss: 0.0900\n",
      "Epoch [810/6000], Loss: 0.0892\n",
      "Epoch [815/6000], Loss: 0.0884\n",
      "Epoch [820/6000], Loss: 0.0876\n",
      "Epoch [825/6000], Loss: 0.0868\n",
      "Epoch [830/6000], Loss: 0.0861\n",
      "Epoch [835/6000], Loss: 0.0853\n",
      "Epoch [840/6000], Loss: 0.0846\n",
      "Epoch [845/6000], Loss: 0.0838\n",
      "Epoch [850/6000], Loss: 0.0831\n",
      "Epoch [855/6000], Loss: 0.0824\n",
      "Epoch [860/6000], Loss: 0.0817\n",
      "Epoch [865/6000], Loss: 0.0810\n",
      "Epoch [870/6000], Loss: 0.0803\n",
      "Epoch [875/6000], Loss: 0.0796\n",
      "Epoch [880/6000], Loss: 0.0789\n",
      "Epoch [885/6000], Loss: 0.0783\n",
      "Epoch [890/6000], Loss: 0.0776\n",
      "Epoch [895/6000], Loss: 0.0770\n",
      "Epoch [900/6000], Loss: 0.0763\n",
      "Epoch [905/6000], Loss: 0.0757\n",
      "Epoch [910/6000], Loss: 0.0751\n",
      "Epoch [915/6000], Loss: 0.0744\n",
      "Epoch [920/6000], Loss: 0.0738\n",
      "Epoch [925/6000], Loss: 0.0732\n",
      "Epoch [930/6000], Loss: 0.0726\n",
      "Epoch [935/6000], Loss: 0.0720\n",
      "Epoch [940/6000], Loss: 0.0715\n",
      "Epoch [945/6000], Loss: 0.0709\n",
      "Epoch [950/6000], Loss: 0.0703\n",
      "Epoch [955/6000], Loss: 0.0697\n",
      "Epoch [960/6000], Loss: 0.0692\n",
      "Epoch [965/6000], Loss: 0.0686\n",
      "Epoch [970/6000], Loss: 0.0681\n",
      "Epoch [975/6000], Loss: 0.0675\n",
      "Epoch [980/6000], Loss: 0.0670\n",
      "Epoch [985/6000], Loss: 0.0665\n",
      "Epoch [990/6000], Loss: 0.0660\n",
      "Epoch [995/6000], Loss: 0.0654\n",
      "Epoch [1000/6000], Loss: 0.0649\n",
      "Epoch [1005/6000], Loss: 0.0644\n",
      "Epoch [1010/6000], Loss: 0.0639\n",
      "Epoch [1015/6000], Loss: 0.0634\n",
      "Epoch [1020/6000], Loss: 0.0629\n",
      "Epoch [1025/6000], Loss: 0.0625\n",
      "Epoch [1030/6000], Loss: 0.0620\n",
      "Epoch [1035/6000], Loss: 0.0615\n",
      "Epoch [1040/6000], Loss: 0.0611\n",
      "Epoch [1045/6000], Loss: 0.0607\n",
      "Epoch [1050/6000], Loss: 0.0607\n",
      "Epoch [1055/6000], Loss: 0.0617\n",
      "Epoch [1060/6000], Loss: 0.0672\n",
      "Epoch [1065/6000], Loss: 0.0909\n",
      "Epoch [1070/6000], Loss: 0.1943\n",
      "Epoch [1075/6000], Loss: 0.6541\n",
      "Epoch [1080/6000], Loss: 2.0743\n",
      "Epoch [1085/6000], Loss: 1.1095\n",
      "Epoch [1090/6000], Loss: 0.6889\n",
      "Epoch [1095/6000], Loss: 1.6911\n",
      "Epoch [1100/6000], Loss: 0.6188\n",
      "Epoch [1105/6000], Loss: 0.2182\n",
      "Epoch [1110/6000], Loss: 0.9046\n",
      "Epoch [1115/6000], Loss: 2.1017\n",
      "Epoch [1120/6000], Loss: 1.5215\n",
      "Epoch [1125/6000], Loss: 0.2907\n",
      "Epoch [1130/6000], Loss: 1.1910\n",
      "Epoch [1135/6000], Loss: 1.0829\n",
      "Epoch [1140/6000], Loss: 0.4561\n",
      "Epoch [1145/6000], Loss: 0.0771\n",
      "Epoch [1150/6000], Loss: 0.1038\n",
      "Epoch [1155/6000], Loss: 0.1493\n",
      "Epoch [1160/6000], Loss: 0.0897\n",
      "Epoch [1165/6000], Loss: 0.0558\n",
      "Epoch [1170/6000], Loss: 0.0657\n",
      "Epoch [1175/6000], Loss: 0.0675\n",
      "Epoch [1180/6000], Loss: 0.0584\n",
      "Epoch [1185/6000], Loss: 0.0541\n",
      "Epoch [1190/6000], Loss: 0.0547\n",
      "Epoch [1195/6000], Loss: 0.0550\n",
      "Epoch [1200/6000], Loss: 0.0538\n",
      "Epoch [1205/6000], Loss: 0.0527\n",
      "Epoch [1210/6000], Loss: 0.0521\n",
      "Epoch [1215/6000], Loss: 0.0517\n",
      "Epoch [1220/6000], Loss: 0.0514\n",
      "Epoch [1225/6000], Loss: 0.0510\n",
      "Epoch [1230/6000], Loss: 0.0506\n",
      "Epoch [1235/6000], Loss: 0.0502\n",
      "Epoch [1240/6000], Loss: 0.0498\n",
      "Epoch [1245/6000], Loss: 0.0495\n",
      "Epoch [1250/6000], Loss: 0.0491\n",
      "Epoch [1255/6000], Loss: 0.0487\n",
      "Epoch [1260/6000], Loss: 0.0484\n",
      "Epoch [1265/6000], Loss: 0.0480\n",
      "Epoch [1270/6000], Loss: 0.0477\n",
      "Epoch [1275/6000], Loss: 0.0474\n",
      "Epoch [1280/6000], Loss: 0.0471\n",
      "Epoch [1285/6000], Loss: 0.0468\n",
      "Epoch [1290/6000], Loss: 0.0465\n",
      "Epoch [1295/6000], Loss: 0.0464\n",
      "Epoch [1300/6000], Loss: 0.0467\n",
      "Epoch [1305/6000], Loss: 0.0478\n",
      "Epoch [1310/6000], Loss: 0.0516\n",
      "Epoch [1315/6000], Loss: 0.0635\n",
      "Epoch [1320/6000], Loss: 0.1007\n",
      "Epoch [1325/6000], Loss: 0.2218\n",
      "Epoch [1330/6000], Loss: 0.6229\n",
      "Epoch [1335/6000], Loss: 1.9437\n",
      "Epoch [1340/6000], Loss: 1.5800\n",
      "Epoch [1345/6000], Loss: 0.2461\n",
      "Epoch [1350/6000], Loss: 1.3382\n",
      "Epoch [1355/6000], Loss: 0.5690\n",
      "Epoch [1360/6000], Loss: 0.1440\n",
      "Epoch [1365/6000], Loss: 0.5840\n",
      "Epoch [1370/6000], Loss: 1.0166\n",
      "Epoch [1375/6000], Loss: 1.3487\n",
      "Epoch [1380/6000], Loss: 0.2106\n",
      "Epoch [1385/6000], Loss: 0.3663\n",
      "Epoch [1390/6000], Loss: 0.3911\n",
      "Epoch [1395/6000], Loss: 0.2109\n",
      "Epoch [1400/6000], Loss: 0.0823\n",
      "Epoch [1405/6000], Loss: 0.0435\n",
      "Epoch [1410/6000], Loss: 0.0498\n",
      "Epoch [1415/6000], Loss: 0.0589\n",
      "Epoch [1420/6000], Loss: 0.0579\n",
      "Epoch [1425/6000], Loss: 0.0514\n",
      "Epoch [1430/6000], Loss: 0.0455\n",
      "Epoch [1435/6000], Loss: 0.0422\n",
      "Epoch [1440/6000], Loss: 0.0408\n",
      "Epoch [1445/6000], Loss: 0.0403\n",
      "Epoch [1450/6000], Loss: 0.0401\n",
      "Epoch [1455/6000], Loss: 0.0400\n",
      "Epoch [1460/6000], Loss: 0.0398\n",
      "Epoch [1465/6000], Loss: 0.0396\n",
      "Epoch [1470/6000], Loss: 0.0394\n",
      "Epoch [1475/6000], Loss: 0.0393\n",
      "Epoch [1480/6000], Loss: 0.0394\n",
      "Epoch [1485/6000], Loss: 0.0396\n",
      "Epoch [1490/6000], Loss: 0.0403\n",
      "Epoch [1495/6000], Loss: 0.0419\n",
      "Epoch [1500/6000], Loss: 0.0456\n",
      "Epoch [1505/6000], Loss: 0.0539\n",
      "Epoch [1510/6000], Loss: 0.0733\n",
      "Epoch [1515/6000], Loss: 0.1198\n",
      "Epoch [1520/6000], Loss: 0.2351\n",
      "Epoch [1525/6000], Loss: 0.5240\n",
      "Epoch [1530/6000], Loss: 1.2442\n",
      "Epoch [1535/6000], Loss: 1.5461\n",
      "Epoch [1540/6000], Loss: 0.0732\n",
      "Epoch [1545/6000], Loss: 0.6342\n",
      "Epoch [1550/6000], Loss: 1.2627\n",
      "Epoch [1555/6000], Loss: 1.5836\n",
      "Epoch [1560/6000], Loss: 0.1973\n",
      "Epoch [1565/6000], Loss: 0.4466\n",
      "Epoch [1570/6000], Loss: 0.3421\n",
      "Epoch [1575/6000], Loss: 0.0951\n",
      "Epoch [1580/6000], Loss: 0.0384\n",
      "Epoch [1585/6000], Loss: 0.0727\n",
      "Epoch [1590/6000], Loss: 0.0792\n",
      "Epoch [1595/6000], Loss: 0.0552\n",
      "Epoch [1600/6000], Loss: 0.0377\n",
      "Epoch [1605/6000], Loss: 0.0356\n",
      "Epoch [1610/6000], Loss: 0.0380\n",
      "Epoch [1615/6000], Loss: 0.0382\n",
      "Epoch [1620/6000], Loss: 0.0365\n",
      "Epoch [1625/6000], Loss: 0.0348\n",
      "Epoch [1630/6000], Loss: 0.0339\n",
      "Epoch [1635/6000], Loss: 0.0337\n",
      "Epoch [1640/6000], Loss: 0.0335\n",
      "Epoch [1645/6000], Loss: 0.0334\n",
      "Epoch [1650/6000], Loss: 0.0332\n",
      "Epoch [1655/6000], Loss: 0.0329\n",
      "Epoch [1660/6000], Loss: 0.0327\n",
      "Epoch [1665/6000], Loss: 0.0325\n",
      "Epoch [1670/6000], Loss: 0.0323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1675/6000], Loss: 0.0321\n",
      "Epoch [1680/6000], Loss: 0.0319\n",
      "Epoch [1685/6000], Loss: 0.0317\n",
      "Epoch [1690/6000], Loss: 0.0315\n",
      "Epoch [1695/6000], Loss: 0.0314\n",
      "Epoch [1700/6000], Loss: 0.0312\n",
      "Epoch [1705/6000], Loss: 0.0312\n",
      "Epoch [1710/6000], Loss: 0.0313\n",
      "Epoch [1715/6000], Loss: 0.0316\n",
      "Epoch [1720/6000], Loss: 0.0325\n",
      "Epoch [1725/6000], Loss: 0.0346\n",
      "Epoch [1730/6000], Loss: 0.0396\n",
      "Epoch [1735/6000], Loss: 0.0515\n",
      "Epoch [1740/6000], Loss: 0.0807\n",
      "Epoch [1745/6000], Loss: 0.1543\n",
      "Epoch [1750/6000], Loss: 0.3422\n",
      "Epoch [1755/6000], Loss: 0.8251\n",
      "Epoch [1760/6000], Loss: 1.6920\n",
      "Epoch [1765/6000], Loss: 0.5560\n",
      "Epoch [1770/6000], Loss: 0.3256\n",
      "Epoch [1775/6000], Loss: 1.0275\n",
      "Epoch [1780/6000], Loss: 1.5869\n",
      "Epoch [1785/6000], Loss: 0.8388\n",
      "Epoch [1790/6000], Loss: 0.1950\n",
      "Epoch [1795/6000], Loss: 0.4795\n",
      "Epoch [1800/6000], Loss: 0.1776\n",
      "Epoch [1805/6000], Loss: 0.0325\n",
      "Epoch [1810/6000], Loss: 0.0579\n",
      "Epoch [1815/6000], Loss: 0.0808\n",
      "Epoch [1820/6000], Loss: 0.0572\n",
      "Epoch [1825/6000], Loss: 0.0327\n",
      "Epoch [1830/6000], Loss: 0.0292\n",
      "Epoch [1835/6000], Loss: 0.0328\n",
      "Epoch [1840/6000], Loss: 0.0326\n",
      "Epoch [1845/6000], Loss: 0.0299\n",
      "Epoch [1850/6000], Loss: 0.0281\n",
      "Epoch [1855/6000], Loss: 0.0277\n",
      "Epoch [1860/6000], Loss: 0.0278\n",
      "Epoch [1865/6000], Loss: 0.0277\n",
      "Epoch [1870/6000], Loss: 0.0274\n",
      "Epoch [1875/6000], Loss: 0.0271\n",
      "Epoch [1880/6000], Loss: 0.0269\n",
      "Epoch [1885/6000], Loss: 0.0267\n",
      "Epoch [1890/6000], Loss: 0.0265\n",
      "Epoch [1895/6000], Loss: 0.0264\n",
      "Epoch [1900/6000], Loss: 0.0262\n",
      "Epoch [1905/6000], Loss: 0.0261\n",
      "Epoch [1910/6000], Loss: 0.0259\n",
      "Epoch [1915/6000], Loss: 0.0258\n",
      "Epoch [1920/6000], Loss: 0.0256\n",
      "Epoch [1925/6000], Loss: 0.0255\n",
      "Epoch [1930/6000], Loss: 0.0254\n",
      "Epoch [1935/6000], Loss: 0.0252\n",
      "Epoch [1940/6000], Loss: 0.0251\n",
      "Epoch [1945/6000], Loss: 0.0249\n",
      "Epoch [1950/6000], Loss: 0.0248\n",
      "Epoch [1955/6000], Loss: 0.0247\n",
      "Epoch [1960/6000], Loss: 0.0246\n",
      "Epoch [1965/6000], Loss: 0.0245\n",
      "Epoch [1970/6000], Loss: 0.0244\n",
      "Epoch [1975/6000], Loss: 0.0243\n",
      "Epoch [1980/6000], Loss: 0.0244\n",
      "Epoch [1985/6000], Loss: 0.0247\n",
      "Epoch [1990/6000], Loss: 0.0255\n",
      "Epoch [1995/6000], Loss: 0.0274\n",
      "Epoch [2000/6000], Loss: 0.0318\n",
      "Epoch [2005/6000], Loss: 0.0425\n",
      "Epoch [2010/6000], Loss: 0.0684\n",
      "Epoch [2015/6000], Loss: 0.1330\n",
      "Epoch [2020/6000], Loss: 0.2947\n",
      "Epoch [2025/6000], Loss: 0.7019\n",
      "Epoch [2030/6000], Loss: 1.6567\n",
      "Epoch [2035/6000], Loss: 1.3892\n",
      "Epoch [2040/6000], Loss: 0.0804\n",
      "Epoch [2045/6000], Loss: 0.8206\n",
      "Epoch [2050/6000], Loss: 1.2103\n",
      "Epoch [2055/6000], Loss: 1.0377\n",
      "Epoch [2060/6000], Loss: 0.5107\n",
      "Epoch [2065/6000], Loss: 0.0849\n",
      "Epoch [2070/6000], Loss: 0.0430\n",
      "Epoch [2075/6000], Loss: 0.1053\n",
      "Epoch [2080/6000], Loss: 0.0638\n",
      "Epoch [2085/6000], Loss: 0.0240\n",
      "Epoch [2090/6000], Loss: 0.0315\n",
      "Epoch [2095/6000], Loss: 0.0346\n",
      "Epoch [2100/6000], Loss: 0.0258\n",
      "Epoch [2105/6000], Loss: 0.0227\n",
      "Epoch [2110/6000], Loss: 0.0242\n",
      "Epoch [2115/6000], Loss: 0.0239\n",
      "Epoch [2120/6000], Loss: 0.0226\n",
      "Epoch [2125/6000], Loss: 0.0222\n",
      "Epoch [2130/6000], Loss: 0.0222\n",
      "Epoch [2135/6000], Loss: 0.0221\n",
      "Epoch [2140/6000], Loss: 0.0218\n",
      "Epoch [2145/6000], Loss: 0.0216\n",
      "Epoch [2150/6000], Loss: 0.0215\n",
      "Epoch [2155/6000], Loss: 0.0214\n",
      "Epoch [2160/6000], Loss: 0.0213\n",
      "Epoch [2165/6000], Loss: 0.0211\n",
      "Epoch [2170/6000], Loss: 0.0210\n",
      "Epoch [2175/6000], Loss: 0.0209\n",
      "Epoch [2180/6000], Loss: 0.0208\n",
      "Epoch [2185/6000], Loss: 0.0207\n",
      "Epoch [2190/6000], Loss: 0.0206\n",
      "Epoch [2195/6000], Loss: 0.0205\n",
      "Epoch [2200/6000], Loss: 0.0203\n",
      "Epoch [2205/6000], Loss: 0.0202\n",
      "Epoch [2210/6000], Loss: 0.0201\n",
      "Epoch [2215/6000], Loss: 0.0200\n",
      "Epoch [2220/6000], Loss: 0.0199\n",
      "Epoch [2225/6000], Loss: 0.0198\n",
      "Epoch [2230/6000], Loss: 0.0197\n",
      "Epoch [2235/6000], Loss: 0.0196\n",
      "Epoch [2240/6000], Loss: 0.0195\n",
      "Epoch [2245/6000], Loss: 0.0194\n",
      "Epoch [2250/6000], Loss: 0.0193\n",
      "Epoch [2255/6000], Loss: 0.0192\n",
      "Epoch [2260/6000], Loss: 0.0191\n",
      "Epoch [2265/6000], Loss: 0.0190\n",
      "Epoch [2270/6000], Loss: 0.0189\n",
      "Epoch [2275/6000], Loss: 0.0188\n",
      "Epoch [2280/6000], Loss: 0.0187\n",
      "Epoch [2285/6000], Loss: 0.0186\n",
      "Epoch [2290/6000], Loss: 0.0186\n",
      "Epoch [2295/6000], Loss: 0.0185\n",
      "Epoch [2300/6000], Loss: 0.0184\n",
      "Epoch [2305/6000], Loss: 0.0183\n",
      "Epoch [2310/6000], Loss: 0.0182\n",
      "Epoch [2315/6000], Loss: 0.0181\n",
      "Epoch [2320/6000], Loss: 0.0180\n",
      "Epoch [2325/6000], Loss: 0.0179\n",
      "Epoch [2330/6000], Loss: 0.0179\n",
      "Epoch [2335/6000], Loss: 0.0178\n",
      "Epoch [2340/6000], Loss: 0.0177\n",
      "Epoch [2345/6000], Loss: 0.0176\n",
      "Epoch [2350/6000], Loss: 0.0175\n",
      "Epoch [2355/6000], Loss: 0.0175\n",
      "Epoch [2360/6000], Loss: 0.0175\n",
      "Epoch [2365/6000], Loss: 0.0176\n",
      "Epoch [2370/6000], Loss: 0.0180\n",
      "Epoch [2375/6000], Loss: 0.0189\n",
      "Epoch [2380/6000], Loss: 0.0215\n",
      "Epoch [2385/6000], Loss: 0.0280\n",
      "Epoch [2390/6000], Loss: 0.0449\n",
      "Epoch [2395/6000], Loss: 0.0893\n",
      "Epoch [2400/6000], Loss: 0.2066\n",
      "Epoch [2405/6000], Loss: 0.5185\n",
      "Epoch [2410/6000], Loss: 1.3068\n",
      "Epoch [2415/6000], Loss: 2.2828\n",
      "Epoch [2420/6000], Loss: 0.2736\n",
      "Epoch [2425/6000], Loss: 0.6258\n",
      "Epoch [2430/6000], Loss: 1.2917\n",
      "Epoch [2435/6000], Loss: 1.1637\n",
      "Epoch [2440/6000], Loss: 0.5128\n",
      "Epoch [2445/6000], Loss: 0.0520\n",
      "Epoch [2450/6000], Loss: 0.0645\n",
      "Epoch [2455/6000], Loss: 0.1159\n",
      "Epoch [2460/6000], Loss: 0.0436\n",
      "Epoch [2465/6000], Loss: 0.0188\n",
      "Epoch [2470/6000], Loss: 0.0341\n",
      "Epoch [2475/6000], Loss: 0.0263\n",
      "Epoch [2480/6000], Loss: 0.0171\n",
      "Epoch [2485/6000], Loss: 0.0190\n",
      "Epoch [2490/6000], Loss: 0.0193\n",
      "Epoch [2495/6000], Loss: 0.0171\n",
      "Epoch [2500/6000], Loss: 0.0167\n",
      "Epoch [2505/6000], Loss: 0.0170\n",
      "Epoch [2510/6000], Loss: 0.0167\n",
      "Epoch [2515/6000], Loss: 0.0163\n",
      "Epoch [2520/6000], Loss: 0.0162\n",
      "Epoch [2525/6000], Loss: 0.0162\n",
      "Epoch [2530/6000], Loss: 0.0161\n",
      "Epoch [2535/6000], Loss: 0.0160\n",
      "Epoch [2540/6000], Loss: 0.0159\n",
      "Epoch [2545/6000], Loss: 0.0158\n",
      "Epoch [2550/6000], Loss: 0.0157\n",
      "Epoch [2555/6000], Loss: 0.0156\n",
      "Epoch [2560/6000], Loss: 0.0156\n",
      "Epoch [2565/6000], Loss: 0.0155\n",
      "Epoch [2570/6000], Loss: 0.0154\n",
      "Epoch [2575/6000], Loss: 0.0153\n",
      "Epoch [2580/6000], Loss: 0.0152\n",
      "Epoch [2585/6000], Loss: 0.0152\n",
      "Epoch [2590/6000], Loss: 0.0151\n",
      "Epoch [2595/6000], Loss: 0.0150\n",
      "Epoch [2600/6000], Loss: 0.0150\n",
      "Epoch [2605/6000], Loss: 0.0149\n",
      "Epoch [2610/6000], Loss: 0.0148\n",
      "Epoch [2615/6000], Loss: 0.0147\n",
      "Epoch [2620/6000], Loss: 0.0147\n",
      "Epoch [2625/6000], Loss: 0.0146\n",
      "Epoch [2630/6000], Loss: 0.0145\n",
      "Epoch [2635/6000], Loss: 0.0145\n",
      "Epoch [2640/6000], Loss: 0.0144\n",
      "Epoch [2645/6000], Loss: 0.0143\n",
      "Epoch [2650/6000], Loss: 0.0143\n",
      "Epoch [2655/6000], Loss: 0.0142\n",
      "Epoch [2660/6000], Loss: 0.0141\n",
      "Epoch [2665/6000], Loss: 0.0141\n",
      "Epoch [2670/6000], Loss: 0.0140\n",
      "Epoch [2675/6000], Loss: 0.0140\n",
      "Epoch [2680/6000], Loss: 0.0139\n",
      "Epoch [2685/6000], Loss: 0.0138\n",
      "Epoch [2690/6000], Loss: 0.0138\n",
      "Epoch [2695/6000], Loss: 0.0137\n",
      "Epoch [2700/6000], Loss: 0.0137\n",
      "Epoch [2705/6000], Loss: 0.0136\n",
      "Epoch [2710/6000], Loss: 0.0135\n",
      "Epoch [2715/6000], Loss: 0.0135\n",
      "Epoch [2720/6000], Loss: 0.0134\n",
      "Epoch [2725/6000], Loss: 0.0134\n",
      "Epoch [2730/6000], Loss: 0.0133\n",
      "Epoch [2735/6000], Loss: 0.0133\n",
      "Epoch [2740/6000], Loss: 0.0132\n",
      "Epoch [2745/6000], Loss: 0.0132\n",
      "Epoch [2750/6000], Loss: 0.0131\n",
      "Epoch [2755/6000], Loss: 0.0131\n",
      "Epoch [2760/6000], Loss: 0.0130\n",
      "Epoch [2765/6000], Loss: 0.0129\n",
      "Epoch [2770/6000], Loss: 0.0129\n",
      "Epoch [2775/6000], Loss: 0.0128\n",
      "Epoch [2780/6000], Loss: 0.0128\n",
      "Epoch [2785/6000], Loss: 0.0127\n",
      "Epoch [2790/6000], Loss: 0.0127\n",
      "Epoch [2795/6000], Loss: 0.0126\n",
      "Epoch [2800/6000], Loss: 0.0126\n",
      "Epoch [2805/6000], Loss: 0.0126\n",
      "Epoch [2810/6000], Loss: 0.0125\n",
      "Epoch [2815/6000], Loss: 0.0125\n",
      "Epoch [2820/6000], Loss: 0.0125\n",
      "Epoch [2825/6000], Loss: 0.0125\n",
      "Epoch [2830/6000], Loss: 0.0125\n",
      "Epoch [2835/6000], Loss: 0.0126\n",
      "Epoch [2840/6000], Loss: 0.0129\n",
      "Epoch [2845/6000], Loss: 0.0135\n",
      "Epoch [2850/6000], Loss: 0.0146\n",
      "Epoch [2855/6000], Loss: 0.0171\n",
      "Epoch [2860/6000], Loss: 0.0223\n",
      "Epoch [2865/6000], Loss: 0.0332\n",
      "Epoch [2870/6000], Loss: 0.0561\n",
      "Epoch [2875/6000], Loss: 0.1052\n",
      "Epoch [2880/6000], Loss: 0.2093\n",
      "Epoch [2885/6000], Loss: 0.4281\n",
      "Epoch [2890/6000], Loss: 0.8580\n",
      "Epoch [2895/6000], Loss: 1.6073\n",
      "Epoch [2900/6000], Loss: 2.4717\n",
      "Epoch [2905/6000], Loss: 0.8821\n",
      "Epoch [2910/6000], Loss: 0.3969\n",
      "Epoch [2915/6000], Loss: 0.4738\n",
      "Epoch [2920/6000], Loss: 0.0565\n",
      "Epoch [2925/6000], Loss: 0.0563\n",
      "Epoch [2930/6000], Loss: 0.1113\n",
      "Epoch [2935/6000], Loss: 0.0404\n",
      "Epoch [2940/6000], Loss: 0.0137\n",
      "Epoch [2945/6000], Loss: 0.0294\n",
      "Epoch [2950/6000], Loss: 0.0209\n",
      "Epoch [2955/6000], Loss: 0.0122\n",
      "Epoch [2960/6000], Loss: 0.0147\n",
      "Epoch [2965/6000], Loss: 0.0144\n",
      "Epoch [2970/6000], Loss: 0.0122\n",
      "Epoch [2975/6000], Loss: 0.0121\n",
      "Epoch [2980/6000], Loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2985/6000], Loss: 0.0119\n",
      "Epoch [2990/6000], Loss: 0.0117\n",
      "Epoch [2995/6000], Loss: 0.0117\n",
      "Epoch [3000/6000], Loss: 0.0117\n",
      "Epoch [3005/6000], Loss: 0.0116\n",
      "Epoch [3010/6000], Loss: 0.0115\n",
      "Epoch [3015/6000], Loss: 0.0115\n",
      "Epoch [3020/6000], Loss: 0.0114\n",
      "Epoch [3025/6000], Loss: 0.0114\n",
      "Epoch [3030/6000], Loss: 0.0113\n",
      "Epoch [3035/6000], Loss: 0.0113\n",
      "Epoch [3040/6000], Loss: 0.0112\n",
      "Epoch [3045/6000], Loss: 0.0112\n",
      "Epoch [3050/6000], Loss: 0.0111\n",
      "Epoch [3055/6000], Loss: 0.0111\n",
      "Epoch [3060/6000], Loss: 0.0110\n",
      "Epoch [3065/6000], Loss: 0.0110\n",
      "Epoch [3070/6000], Loss: 0.0109\n",
      "Epoch [3075/6000], Loss: 0.0109\n",
      "Epoch [3080/6000], Loss: 0.0108\n",
      "Epoch [3085/6000], Loss: 0.0108\n",
      "Epoch [3090/6000], Loss: 0.0108\n",
      "Epoch [3095/6000], Loss: 0.0107\n",
      "Epoch [3100/6000], Loss: 0.0107\n",
      "Epoch [3105/6000], Loss: 0.0106\n",
      "Epoch [3110/6000], Loss: 0.0106\n",
      "Epoch [3115/6000], Loss: 0.0105\n",
      "Epoch [3120/6000], Loss: 0.0105\n",
      "Epoch [3125/6000], Loss: 0.0105\n",
      "Epoch [3130/6000], Loss: 0.0104\n",
      "Epoch [3135/6000], Loss: 0.0104\n",
      "Epoch [3140/6000], Loss: 0.0103\n",
      "Epoch [3145/6000], Loss: 0.0103\n",
      "Epoch [3150/6000], Loss: 0.0103\n",
      "Epoch [3155/6000], Loss: 0.0102\n",
      "Epoch [3160/6000], Loss: 0.0102\n",
      "Epoch [3165/6000], Loss: 0.0102\n",
      "Epoch [3170/6000], Loss: 0.0101\n",
      "Epoch [3175/6000], Loss: 0.0101\n",
      "Epoch [3180/6000], Loss: 0.0101\n",
      "Epoch [3185/6000], Loss: 0.0100\n",
      "Epoch [3190/6000], Loss: 0.0100\n",
      "Epoch [3195/6000], Loss: 0.0099\n",
      "Epoch [3200/6000], Loss: 0.0099\n",
      "Epoch [3205/6000], Loss: 0.0099\n",
      "Epoch [3210/6000], Loss: 0.0098\n",
      "Epoch [3215/6000], Loss: 0.0098\n",
      "Epoch [3220/6000], Loss: 0.0098\n",
      "Epoch [3225/6000], Loss: 0.0097\n",
      "Epoch [3230/6000], Loss: 0.0097\n",
      "Epoch [3235/6000], Loss: 0.0097\n",
      "Epoch [3240/6000], Loss: 0.0096\n",
      "Epoch [3245/6000], Loss: 0.0096\n",
      "Epoch [3250/6000], Loss: 0.0096\n",
      "Epoch [3255/6000], Loss: 0.0095\n",
      "Epoch [3260/6000], Loss: 0.0095\n",
      "Epoch [3265/6000], Loss: 0.0095\n",
      "Epoch [3270/6000], Loss: 0.0095\n",
      "Epoch [3275/6000], Loss: 0.0094\n",
      "Epoch [3280/6000], Loss: 0.0094\n",
      "Epoch [3285/6000], Loss: 0.0094\n",
      "Epoch [3290/6000], Loss: 0.0093\n",
      "Epoch [3295/6000], Loss: 0.0093\n",
      "Epoch [3300/6000], Loss: 0.0093\n",
      "Epoch [3305/6000], Loss: 0.0092\n",
      "Epoch [3310/6000], Loss: 0.0092\n",
      "Epoch [3315/6000], Loss: 0.0092\n",
      "Epoch [3320/6000], Loss: 0.0092\n",
      "Epoch [3325/6000], Loss: 0.0091\n",
      "Epoch [3330/6000], Loss: 0.0091\n",
      "Epoch [3335/6000], Loss: 0.0091\n",
      "Epoch [3340/6000], Loss: 0.0090\n",
      "Epoch [3345/6000], Loss: 0.0090\n",
      "Epoch [3350/6000], Loss: 0.0090\n",
      "Epoch [3355/6000], Loss: 0.0090\n",
      "Epoch [3360/6000], Loss: 0.0089\n",
      "Epoch [3365/6000], Loss: 0.0089\n",
      "Epoch [3370/6000], Loss: 0.0089\n",
      "Epoch [3375/6000], Loss: 0.0089\n",
      "Epoch [3380/6000], Loss: 0.0088\n",
      "Epoch [3385/6000], Loss: 0.0088\n",
      "Epoch [3390/6000], Loss: 0.0088\n",
      "Epoch [3395/6000], Loss: 0.0088\n",
      "Epoch [3400/6000], Loss: 0.0087\n",
      "Epoch [3405/6000], Loss: 0.0087\n",
      "Epoch [3410/6000], Loss: 0.0087\n",
      "Epoch [3415/6000], Loss: 0.0086\n",
      "Epoch [3420/6000], Loss: 0.0086\n",
      "Epoch [3425/6000], Loss: 0.0086\n",
      "Epoch [3430/6000], Loss: 0.0086\n",
      "Epoch [3435/6000], Loss: 0.0086\n",
      "Epoch [3440/6000], Loss: 0.0085\n",
      "Epoch [3445/6000], Loss: 0.0085\n",
      "Epoch [3450/6000], Loss: 0.0085\n",
      "Epoch [3455/6000], Loss: 0.0085\n",
      "Epoch [3460/6000], Loss: 0.0084\n",
      "Epoch [3465/6000], Loss: 0.0084\n",
      "Epoch [3470/6000], Loss: 0.0084\n",
      "Epoch [3475/6000], Loss: 0.0084\n",
      "Epoch [3480/6000], Loss: 0.0083\n",
      "Epoch [3485/6000], Loss: 0.0083\n",
      "Epoch [3490/6000], Loss: 0.0083\n",
      "Epoch [3495/6000], Loss: 0.0083\n",
      "Epoch [3500/6000], Loss: 0.0082\n",
      "Epoch [3505/6000], Loss: 0.0082\n",
      "Epoch [3510/6000], Loss: 0.0082\n",
      "Epoch [3515/6000], Loss: 0.0082\n",
      "Epoch [3520/6000], Loss: 0.0082\n",
      "Epoch [3525/6000], Loss: 0.0081\n",
      "Epoch [3530/6000], Loss: 0.0081\n",
      "Epoch [3535/6000], Loss: 0.0081\n",
      "Epoch [3540/6000], Loss: 0.0081\n",
      "Epoch [3545/6000], Loss: 0.0081\n",
      "Epoch [3550/6000], Loss: 0.0081\n",
      "Epoch [3555/6000], Loss: 0.0081\n",
      "Epoch [3560/6000], Loss: 0.0082\n",
      "Epoch [3565/6000], Loss: 0.0083\n",
      "Epoch [3570/6000], Loss: 0.0086\n",
      "Epoch [3575/6000], Loss: 0.0090\n",
      "Epoch [3580/6000], Loss: 0.0099\n",
      "Epoch [3585/6000], Loss: 0.0114\n",
      "Epoch [3590/6000], Loss: 0.0142\n",
      "Epoch [3595/6000], Loss: 0.0194\n",
      "Epoch [3600/6000], Loss: 0.0290\n",
      "Epoch [3605/6000], Loss: 0.0466\n",
      "Epoch [3610/6000], Loss: 0.0791\n",
      "Epoch [3615/6000], Loss: 0.1382\n",
      "Epoch [3620/6000], Loss: 0.2443\n",
      "Epoch [3625/6000], Loss: 0.4238\n",
      "Epoch [3630/6000], Loss: 0.7052\n",
      "Epoch [3635/6000], Loss: 1.0544\n",
      "Epoch [3640/6000], Loss: 1.3150\n",
      "Epoch [3645/6000], Loss: 1.1525\n",
      "Epoch [3650/6000], Loss: 0.5404\n",
      "Epoch [3655/6000], Loss: 0.0535\n",
      "Epoch [3660/6000], Loss: 0.0495\n",
      "Epoch [3665/6000], Loss: 0.1091\n",
      "Epoch [3670/6000], Loss: 0.0373\n",
      "Epoch [3675/6000], Loss: 0.0092\n",
      "Epoch [3680/6000], Loss: 0.0252\n",
      "Epoch [3685/6000], Loss: 0.0169\n",
      "Epoch [3690/6000], Loss: 0.0080\n",
      "Epoch [3695/6000], Loss: 0.0106\n",
      "Epoch [3700/6000], Loss: 0.0103\n",
      "Epoch [3705/6000], Loss: 0.0081\n",
      "Epoch [3710/6000], Loss: 0.0081\n",
      "Epoch [3715/6000], Loss: 0.0084\n",
      "Epoch [3720/6000], Loss: 0.0079\n",
      "Epoch [3725/6000], Loss: 0.0078\n",
      "Epoch [3730/6000], Loss: 0.0078\n",
      "Epoch [3735/6000], Loss: 0.0078\n",
      "Epoch [3740/6000], Loss: 0.0077\n",
      "Epoch [3745/6000], Loss: 0.0077\n",
      "Epoch [3750/6000], Loss: 0.0076\n",
      "Epoch [3755/6000], Loss: 0.0076\n",
      "Epoch [3760/6000], Loss: 0.0076\n",
      "Epoch [3765/6000], Loss: 0.0076\n",
      "Epoch [3770/6000], Loss: 0.0075\n",
      "Epoch [3775/6000], Loss: 0.0075\n",
      "Epoch [3780/6000], Loss: 0.0075\n",
      "Epoch [3785/6000], Loss: 0.0075\n",
      "Epoch [3790/6000], Loss: 0.0074\n",
      "Epoch [3795/6000], Loss: 0.0074\n",
      "Epoch [3800/6000], Loss: 0.0074\n",
      "Epoch [3805/6000], Loss: 0.0074\n",
      "Epoch [3810/6000], Loss: 0.0073\n",
      "Epoch [3815/6000], Loss: 0.0073\n",
      "Epoch [3820/6000], Loss: 0.0073\n",
      "Epoch [3825/6000], Loss: 0.0073\n",
      "Epoch [3830/6000], Loss: 0.0072\n",
      "Epoch [3835/6000], Loss: 0.0072\n",
      "Epoch [3840/6000], Loss: 0.0072\n",
      "Epoch [3845/6000], Loss: 0.0072\n",
      "Epoch [3850/6000], Loss: 0.0072\n",
      "Epoch [3855/6000], Loss: 0.0071\n",
      "Epoch [3860/6000], Loss: 0.0071\n",
      "Epoch [3865/6000], Loss: 0.0071\n",
      "Epoch [3870/6000], Loss: 0.0071\n",
      "Epoch [3875/6000], Loss: 0.0071\n",
      "Epoch [3880/6000], Loss: 0.0070\n",
      "Epoch [3885/6000], Loss: 0.0070\n",
      "Epoch [3890/6000], Loss: 0.0070\n",
      "Epoch [3895/6000], Loss: 0.0070\n",
      "Epoch [3900/6000], Loss: 0.0070\n",
      "Epoch [3905/6000], Loss: 0.0069\n",
      "Epoch [3910/6000], Loss: 0.0069\n",
      "Epoch [3915/6000], Loss: 0.0069\n",
      "Epoch [3920/6000], Loss: 0.0069\n",
      "Epoch [3925/6000], Loss: 0.0069\n",
      "Epoch [3930/6000], Loss: 0.0069\n",
      "Epoch [3935/6000], Loss: 0.0068\n",
      "Epoch [3940/6000], Loss: 0.0068\n",
      "Epoch [3945/6000], Loss: 0.0068\n",
      "Epoch [3950/6000], Loss: 0.0068\n",
      "Epoch [3955/6000], Loss: 0.0068\n",
      "Epoch [3960/6000], Loss: 0.0068\n",
      "Epoch [3965/6000], Loss: 0.0067\n",
      "Epoch [3970/6000], Loss: 0.0067\n",
      "Epoch [3975/6000], Loss: 0.0067\n",
      "Epoch [3980/6000], Loss: 0.0067\n",
      "Epoch [3985/6000], Loss: 0.0067\n",
      "Epoch [3990/6000], Loss: 0.0067\n",
      "Epoch [3995/6000], Loss: 0.0066\n",
      "Epoch [4000/6000], Loss: 0.0066\n",
      "Epoch [4005/6000], Loss: 0.0066\n",
      "Epoch [4010/6000], Loss: 0.0066\n",
      "Epoch [4015/6000], Loss: 0.0066\n",
      "Epoch [4020/6000], Loss: 0.0066\n",
      "Epoch [4025/6000], Loss: 0.0066\n",
      "Epoch [4030/6000], Loss: 0.0065\n",
      "Epoch [4035/6000], Loss: 0.0065\n",
      "Epoch [4040/6000], Loss: 0.0065\n",
      "Epoch [4045/6000], Loss: 0.0065\n",
      "Epoch [4050/6000], Loss: 0.0065\n",
      "Epoch [4055/6000], Loss: 0.0065\n",
      "Epoch [4060/6000], Loss: 0.0065\n",
      "Epoch [4065/6000], Loss: 0.0064\n",
      "Epoch [4070/6000], Loss: 0.0064\n",
      "Epoch [4075/6000], Loss: 0.0064\n",
      "Epoch [4080/6000], Loss: 0.0064\n",
      "Epoch [4085/6000], Loss: 0.0064\n",
      "Epoch [4090/6000], Loss: 0.0064\n",
      "Epoch [4095/6000], Loss: 0.0064\n",
      "Epoch [4100/6000], Loss: 0.0064\n",
      "Epoch [4105/6000], Loss: 0.0063\n",
      "Epoch [4110/6000], Loss: 0.0063\n",
      "Epoch [4115/6000], Loss: 0.0063\n",
      "Epoch [4120/6000], Loss: 0.0063\n",
      "Epoch [4125/6000], Loss: 0.0063\n",
      "Epoch [4130/6000], Loss: 0.0063\n",
      "Epoch [4135/6000], Loss: 0.0063\n",
      "Epoch [4140/6000], Loss: 0.0063\n",
      "Epoch [4145/6000], Loss: 0.0062\n",
      "Epoch [4150/6000], Loss: 0.0062\n",
      "Epoch [4155/6000], Loss: 0.0062\n",
      "Epoch [4160/6000], Loss: 0.0062\n",
      "Epoch [4165/6000], Loss: 0.0062\n",
      "Epoch [4170/6000], Loss: 0.0062\n",
      "Epoch [4175/6000], Loss: 0.0062\n",
      "Epoch [4180/6000], Loss: 0.0062\n",
      "Epoch [4185/6000], Loss: 0.0061\n",
      "Epoch [4190/6000], Loss: 0.0061\n",
      "Epoch [4195/6000], Loss: 0.0061\n",
      "Epoch [4200/6000], Loss: 0.0061\n",
      "Epoch [4205/6000], Loss: 0.0061\n",
      "Epoch [4210/6000], Loss: 0.0061\n",
      "Epoch [4215/6000], Loss: 0.0061\n",
      "Epoch [4220/6000], Loss: 0.0061\n",
      "Epoch [4225/6000], Loss: 0.0061\n",
      "Epoch [4230/6000], Loss: 0.0060\n",
      "Epoch [4235/6000], Loss: 0.0060\n",
      "Epoch [4240/6000], Loss: 0.0060\n",
      "Epoch [4245/6000], Loss: 0.0060\n",
      "Epoch [4250/6000], Loss: 0.0060\n",
      "Epoch [4255/6000], Loss: 0.0060\n",
      "Epoch [4260/6000], Loss: 0.0060\n",
      "Epoch [4265/6000], Loss: 0.0060\n",
      "Epoch [4270/6000], Loss: 0.0060\n",
      "Epoch [4275/6000], Loss: 0.0059\n",
      "Epoch [4280/6000], Loss: 0.0059\n",
      "Epoch [4285/6000], Loss: 0.0059\n",
      "Epoch [4290/6000], Loss: 0.0059\n",
      "Epoch [4295/6000], Loss: 0.0059\n",
      "Epoch [4300/6000], Loss: 0.0059\n",
      "Epoch [4305/6000], Loss: 0.0059\n",
      "Epoch [4310/6000], Loss: 0.0059\n",
      "Epoch [4315/6000], Loss: 0.0059\n",
      "Epoch [4320/6000], Loss: 0.0059\n",
      "Epoch [4325/6000], Loss: 0.0058\n",
      "Epoch [4330/6000], Loss: 0.0058\n",
      "Epoch [4335/6000], Loss: 0.0058\n",
      "Epoch [4340/6000], Loss: 0.0058\n",
      "Epoch [4345/6000], Loss: 0.0058\n",
      "Epoch [4350/6000], Loss: 0.0058\n",
      "Epoch [4355/6000], Loss: 0.0058\n",
      "Epoch [4360/6000], Loss: 0.0058\n",
      "Epoch [4365/6000], Loss: 0.0058\n",
      "Epoch [4370/6000], Loss: 0.0058\n",
      "Epoch [4375/6000], Loss: 0.0058\n",
      "Epoch [4380/6000], Loss: 0.0057\n",
      "Epoch [4385/6000], Loss: 0.0057\n",
      "Epoch [4390/6000], Loss: 0.0057\n",
      "Epoch [4395/6000], Loss: 0.0057\n",
      "Epoch [4400/6000], Loss: 0.0057\n",
      "Epoch [4405/6000], Loss: 0.0057\n",
      "Epoch [4410/6000], Loss: 0.0057\n",
      "Epoch [4415/6000], Loss: 0.0057\n",
      "Epoch [4420/6000], Loss: 0.0057\n",
      "Epoch [4425/6000], Loss: 0.0057\n",
      "Epoch [4430/6000], Loss: 0.0057\n",
      "Epoch [4435/6000], Loss: 0.0056\n",
      "Epoch [4440/6000], Loss: 0.0056\n",
      "Epoch [4445/6000], Loss: 0.0056\n",
      "Epoch [4450/6000], Loss: 0.0056\n",
      "Epoch [4455/6000], Loss: 0.0056\n",
      "Epoch [4460/6000], Loss: 0.0056\n",
      "Epoch [4465/6000], Loss: 0.0056\n",
      "Epoch [4470/6000], Loss: 0.0056\n",
      "Epoch [4475/6000], Loss: 0.0056\n",
      "Epoch [4480/6000], Loss: 0.0056\n",
      "Epoch [4485/6000], Loss: 0.0056\n",
      "Epoch [4490/6000], Loss: 0.0056\n",
      "Epoch [4495/6000], Loss: 0.0055\n",
      "Epoch [4500/6000], Loss: 0.0055\n",
      "Epoch [4505/6000], Loss: 0.0055\n",
      "Epoch [4510/6000], Loss: 0.0055\n",
      "Epoch [4515/6000], Loss: 0.0055\n",
      "Epoch [4520/6000], Loss: 0.0055\n",
      "Epoch [4525/6000], Loss: 0.0055\n",
      "Epoch [4530/6000], Loss: 0.0055\n",
      "Epoch [4535/6000], Loss: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4540/6000], Loss: 0.0055\n",
      "Epoch [4545/6000], Loss: 0.0055\n",
      "Epoch [4550/6000], Loss: 0.0055\n",
      "Epoch [4555/6000], Loss: 0.0055\n",
      "Epoch [4560/6000], Loss: 0.0054\n",
      "Epoch [4565/6000], Loss: 0.0054\n",
      "Epoch [4570/6000], Loss: 0.0054\n",
      "Epoch [4575/6000], Loss: 0.0054\n",
      "Epoch [4580/6000], Loss: 0.0054\n",
      "Epoch [4585/6000], Loss: 0.0054\n",
      "Epoch [4590/6000], Loss: 0.0054\n",
      "Epoch [4595/6000], Loss: 0.0054\n",
      "Epoch [4600/6000], Loss: 0.0054\n",
      "Epoch [4605/6000], Loss: 0.0054\n",
      "Epoch [4610/6000], Loss: 0.0054\n",
      "Epoch [4615/6000], Loss: 0.0054\n",
      "Epoch [4620/6000], Loss: 0.0054\n",
      "Epoch [4625/6000], Loss: 0.0053\n",
      "Epoch [4630/6000], Loss: 0.0053\n",
      "Epoch [4635/6000], Loss: 0.0053\n",
      "Epoch [4640/6000], Loss: 0.0053\n",
      "Epoch [4645/6000], Loss: 0.0053\n",
      "Epoch [4650/6000], Loss: 0.0053\n",
      "Epoch [4655/6000], Loss: 0.0053\n",
      "Epoch [4660/6000], Loss: 0.0053\n",
      "Epoch [4665/6000], Loss: 0.0053\n",
      "Epoch [4670/6000], Loss: 0.0053\n",
      "Epoch [4675/6000], Loss: 0.0053\n",
      "Epoch [4680/6000], Loss: 0.0053\n",
      "Epoch [4685/6000], Loss: 0.0053\n",
      "Epoch [4690/6000], Loss: 0.0053\n",
      "Epoch [4695/6000], Loss: 0.0053\n",
      "Epoch [4700/6000], Loss: 0.0052\n",
      "Epoch [4705/6000], Loss: 0.0052\n",
      "Epoch [4710/6000], Loss: 0.0052\n",
      "Epoch [4715/6000], Loss: 0.0052\n",
      "Epoch [4720/6000], Loss: 0.0052\n",
      "Epoch [4725/6000], Loss: 0.0052\n",
      "Epoch [4730/6000], Loss: 0.0052\n",
      "Epoch [4735/6000], Loss: 0.0052\n",
      "Epoch [4740/6000], Loss: 0.0052\n",
      "Epoch [4745/6000], Loss: 0.0052\n",
      "Epoch [4750/6000], Loss: 0.0052\n",
      "Epoch [4755/6000], Loss: 0.0052\n",
      "Epoch [4760/6000], Loss: 0.0052\n",
      "Epoch [4765/6000], Loss: 0.0052\n",
      "Epoch [4770/6000], Loss: 0.0052\n",
      "Epoch [4775/6000], Loss: 0.0052\n",
      "Epoch [4780/6000], Loss: 0.0052\n",
      "Epoch [4785/6000], Loss: 0.0052\n",
      "Epoch [4790/6000], Loss: 0.0052\n",
      "Epoch [4795/6000], Loss: 0.0052\n",
      "Epoch [4800/6000], Loss: 0.0053\n",
      "Epoch [4805/6000], Loss: 0.0053\n",
      "Epoch [4810/6000], Loss: 0.0053\n",
      "Epoch [4815/6000], Loss: 0.0054\n",
      "Epoch [4820/6000], Loss: 0.0055\n",
      "Epoch [4825/6000], Loss: 0.0056\n",
      "Epoch [4830/6000], Loss: 0.0057\n",
      "Epoch [4835/6000], Loss: 0.0059\n",
      "Epoch [4840/6000], Loss: 0.0061\n",
      "Epoch [4845/6000], Loss: 0.0064\n",
      "Epoch [4850/6000], Loss: 0.0068\n",
      "Epoch [4855/6000], Loss: 0.0073\n",
      "Epoch [4860/6000], Loss: 0.0080\n",
      "Epoch [4865/6000], Loss: 0.0088\n",
      "Epoch [4870/6000], Loss: 0.0099\n",
      "Epoch [4875/6000], Loss: 0.0114\n",
      "Epoch [4880/6000], Loss: 0.0133\n",
      "Epoch [4885/6000], Loss: 0.0158\n",
      "Epoch [4890/6000], Loss: 0.0190\n",
      "Epoch [4895/6000], Loss: 0.0231\n",
      "Epoch [4900/6000], Loss: 0.0284\n",
      "Epoch [4905/6000], Loss: 0.0350\n",
      "Epoch [4910/6000], Loss: 0.0433\n",
      "Epoch [4915/6000], Loss: 0.0533\n",
      "Epoch [4920/6000], Loss: 0.0652\n",
      "Epoch [4925/6000], Loss: 0.0786\n",
      "Epoch [4930/6000], Loss: 0.0930\n",
      "Epoch [4935/6000], Loss: 0.1068\n",
      "Epoch [4940/6000], Loss: 0.1185\n",
      "Epoch [4945/6000], Loss: 0.1253\n",
      "Epoch [4950/6000], Loss: 0.1254\n",
      "Epoch [4955/6000], Loss: 0.1168\n",
      "Epoch [4960/6000], Loss: 0.1005\n",
      "Epoch [4965/6000], Loss: 0.0786\n",
      "Epoch [4970/6000], Loss: 0.0557\n",
      "Epoch [4975/6000], Loss: 0.0354\n",
      "Epoch [4980/6000], Loss: 0.0205\n",
      "Epoch [4985/6000], Loss: 0.0114\n",
      "Epoch [4990/6000], Loss: 0.0069\n",
      "Epoch [4995/6000], Loss: 0.0052\n",
      "Epoch [5000/6000], Loss: 0.0049\n",
      "Epoch [5005/6000], Loss: 0.0051\n",
      "Epoch [5010/6000], Loss: 0.0052\n",
      "Epoch [5015/6000], Loss: 0.0052\n",
      "Epoch [5020/6000], Loss: 0.0051\n",
      "Epoch [5025/6000], Loss: 0.0051\n",
      "Epoch [5030/6000], Loss: 0.0050\n",
      "Epoch [5035/6000], Loss: 0.0049\n",
      "Epoch [5040/6000], Loss: 0.0049\n",
      "Epoch [5045/6000], Loss: 0.0049\n",
      "Epoch [5050/6000], Loss: 0.0049\n",
      "Epoch [5055/6000], Loss: 0.0049\n",
      "Epoch [5060/6000], Loss: 0.0049\n",
      "Epoch [5065/6000], Loss: 0.0049\n",
      "Epoch [5070/6000], Loss: 0.0049\n",
      "Epoch [5075/6000], Loss: 0.0049\n",
      "Epoch [5080/6000], Loss: 0.0048\n",
      "Epoch [5085/6000], Loss: 0.0048\n",
      "Epoch [5090/6000], Loss: 0.0048\n",
      "Epoch [5095/6000], Loss: 0.0048\n",
      "Epoch [5100/6000], Loss: 0.0048\n",
      "Epoch [5105/6000], Loss: 0.0048\n",
      "Epoch [5110/6000], Loss: 0.0048\n",
      "Epoch [5115/6000], Loss: 0.0048\n",
      "Epoch [5120/6000], Loss: 0.0048\n",
      "Epoch [5125/6000], Loss: 0.0048\n",
      "Epoch [5130/6000], Loss: 0.0048\n",
      "Epoch [5135/6000], Loss: 0.0048\n",
      "Epoch [5140/6000], Loss: 0.0048\n",
      "Epoch [5145/6000], Loss: 0.0048\n",
      "Epoch [5150/6000], Loss: 0.0048\n",
      "Epoch [5155/6000], Loss: 0.0048\n",
      "Epoch [5160/6000], Loss: 0.0048\n",
      "Epoch [5165/6000], Loss: 0.0048\n",
      "Epoch [5170/6000], Loss: 0.0048\n",
      "Epoch [5175/6000], Loss: 0.0048\n",
      "Epoch [5180/6000], Loss: 0.0048\n",
      "Epoch [5185/6000], Loss: 0.0048\n",
      "Epoch [5190/6000], Loss: 0.0047\n",
      "Epoch [5195/6000], Loss: 0.0047\n",
      "Epoch [5200/6000], Loss: 0.0047\n",
      "Epoch [5205/6000], Loss: 0.0047\n",
      "Epoch [5210/6000], Loss: 0.0047\n",
      "Epoch [5215/6000], Loss: 0.0047\n",
      "Epoch [5220/6000], Loss: 0.0047\n",
      "Epoch [5225/6000], Loss: 0.0047\n",
      "Epoch [5230/6000], Loss: 0.0047\n",
      "Epoch [5235/6000], Loss: 0.0047\n",
      "Epoch [5240/6000], Loss: 0.0047\n",
      "Epoch [5245/6000], Loss: 0.0047\n",
      "Epoch [5250/6000], Loss: 0.0047\n",
      "Epoch [5255/6000], Loss: 0.0047\n",
      "Epoch [5260/6000], Loss: 0.0047\n",
      "Epoch [5265/6000], Loss: 0.0047\n",
      "Epoch [5270/6000], Loss: 0.0047\n",
      "Epoch [5275/6000], Loss: 0.0047\n",
      "Epoch [5280/6000], Loss: 0.0047\n",
      "Epoch [5285/6000], Loss: 0.0047\n",
      "Epoch [5290/6000], Loss: 0.0047\n",
      "Epoch [5295/6000], Loss: 0.0047\n",
      "Epoch [5300/6000], Loss: 0.0047\n",
      "Epoch [5305/6000], Loss: 0.0047\n",
      "Epoch [5310/6000], Loss: 0.0047\n",
      "Epoch [5315/6000], Loss: 0.0047\n",
      "Epoch [5320/6000], Loss: 0.0046\n",
      "Epoch [5325/6000], Loss: 0.0046\n",
      "Epoch [5330/6000], Loss: 0.0046\n",
      "Epoch [5335/6000], Loss: 0.0046\n",
      "Epoch [5340/6000], Loss: 0.0046\n",
      "Epoch [5345/6000], Loss: 0.0046\n",
      "Epoch [5350/6000], Loss: 0.0046\n",
      "Epoch [5355/6000], Loss: 0.0046\n",
      "Epoch [5360/6000], Loss: 0.0046\n",
      "Epoch [5365/6000], Loss: 0.0046\n",
      "Epoch [5370/6000], Loss: 0.0046\n",
      "Epoch [5375/6000], Loss: 0.0046\n",
      "Epoch [5380/6000], Loss: 0.0046\n",
      "Epoch [5385/6000], Loss: 0.0046\n",
      "Epoch [5390/6000], Loss: 0.0046\n",
      "Epoch [5395/6000], Loss: 0.0046\n",
      "Epoch [5400/6000], Loss: 0.0046\n",
      "Epoch [5405/6000], Loss: 0.0046\n",
      "Epoch [5410/6000], Loss: 0.0046\n",
      "Epoch [5415/6000], Loss: 0.0046\n",
      "Epoch [5420/6000], Loss: 0.0046\n",
      "Epoch [5425/6000], Loss: 0.0046\n",
      "Epoch [5430/6000], Loss: 0.0046\n",
      "Epoch [5435/6000], Loss: 0.0046\n",
      "Epoch [5440/6000], Loss: 0.0046\n",
      "Epoch [5445/6000], Loss: 0.0046\n",
      "Epoch [5450/6000], Loss: 0.0046\n",
      "Epoch [5455/6000], Loss: 0.0046\n",
      "Epoch [5460/6000], Loss: 0.0046\n",
      "Epoch [5465/6000], Loss: 0.0045\n",
      "Epoch [5470/6000], Loss: 0.0045\n",
      "Epoch [5475/6000], Loss: 0.0045\n",
      "Epoch [5480/6000], Loss: 0.0045\n",
      "Epoch [5485/6000], Loss: 0.0045\n",
      "Epoch [5490/6000], Loss: 0.0045\n",
      "Epoch [5495/6000], Loss: 0.0045\n",
      "Epoch [5500/6000], Loss: 0.0045\n",
      "Epoch [5505/6000], Loss: 0.0045\n",
      "Epoch [5510/6000], Loss: 0.0045\n",
      "Epoch [5515/6000], Loss: 0.0045\n",
      "Epoch [5520/6000], Loss: 0.0045\n",
      "Epoch [5525/6000], Loss: 0.0045\n",
      "Epoch [5530/6000], Loss: 0.0045\n",
      "Epoch [5535/6000], Loss: 0.0045\n",
      "Epoch [5540/6000], Loss: 0.0045\n",
      "Epoch [5545/6000], Loss: 0.0045\n",
      "Epoch [5550/6000], Loss: 0.0045\n",
      "Epoch [5555/6000], Loss: 0.0045\n",
      "Epoch [5560/6000], Loss: 0.0045\n",
      "Epoch [5565/6000], Loss: 0.0045\n",
      "Epoch [5570/6000], Loss: 0.0045\n",
      "Epoch [5575/6000], Loss: 0.0045\n",
      "Epoch [5580/6000], Loss: 0.0045\n",
      "Epoch [5585/6000], Loss: 0.0045\n",
      "Epoch [5590/6000], Loss: 0.0045\n",
      "Epoch [5595/6000], Loss: 0.0045\n",
      "Epoch [5600/6000], Loss: 0.0045\n",
      "Epoch [5605/6000], Loss: 0.0045\n",
      "Epoch [5610/6000], Loss: 0.0045\n",
      "Epoch [5615/6000], Loss: 0.0045\n",
      "Epoch [5620/6000], Loss: 0.0045\n",
      "Epoch [5625/6000], Loss: 0.0045\n",
      "Epoch [5630/6000], Loss: 0.0045\n",
      "Epoch [5635/6000], Loss: 0.0044\n",
      "Epoch [5640/6000], Loss: 0.0044\n",
      "Epoch [5645/6000], Loss: 0.0044\n",
      "Epoch [5650/6000], Loss: 0.0044\n",
      "Epoch [5655/6000], Loss: 0.0044\n",
      "Epoch [5660/6000], Loss: 0.0044\n",
      "Epoch [5665/6000], Loss: 0.0044\n",
      "Epoch [5670/6000], Loss: 0.0044\n",
      "Epoch [5675/6000], Loss: 0.0044\n",
      "Epoch [5680/6000], Loss: 0.0044\n",
      "Epoch [5685/6000], Loss: 0.0044\n",
      "Epoch [5690/6000], Loss: 0.0044\n",
      "Epoch [5695/6000], Loss: 0.0044\n",
      "Epoch [5700/6000], Loss: 0.0044\n",
      "Epoch [5705/6000], Loss: 0.0044\n",
      "Epoch [5710/6000], Loss: 0.0044\n",
      "Epoch [5715/6000], Loss: 0.0044\n",
      "Epoch [5720/6000], Loss: 0.0044\n",
      "Epoch [5725/6000], Loss: 0.0044\n",
      "Epoch [5730/6000], Loss: 0.0044\n",
      "Epoch [5735/6000], Loss: 0.0044\n",
      "Epoch [5740/6000], Loss: 0.0044\n",
      "Epoch [5745/6000], Loss: 0.0044\n",
      "Epoch [5750/6000], Loss: 0.0044\n",
      "Epoch [5755/6000], Loss: 0.0044\n",
      "Epoch [5760/6000], Loss: 0.0044\n",
      "Epoch [5765/6000], Loss: 0.0044\n",
      "Epoch [5770/6000], Loss: 0.0044\n",
      "Epoch [5775/6000], Loss: 0.0044\n",
      "Epoch [5780/6000], Loss: 0.0044\n",
      "Epoch [5785/6000], Loss: 0.0044\n",
      "Epoch [5790/6000], Loss: 0.0044\n",
      "Epoch [5795/6000], Loss: 0.0044\n",
      "Epoch [5800/6000], Loss: 0.0044\n",
      "Epoch [5805/6000], Loss: 0.0044\n",
      "Epoch [5810/6000], Loss: 0.0044\n",
      "Epoch [5815/6000], Loss: 0.0044\n",
      "Epoch [5820/6000], Loss: 0.0044\n",
      "Epoch [5825/6000], Loss: 0.0044\n",
      "Epoch [5830/6000], Loss: 0.0044\n",
      "Epoch [5835/6000], Loss: 0.0044\n",
      "Epoch [5840/6000], Loss: 0.0044\n",
      "Epoch [5845/6000], Loss: 0.0043\n",
      "Epoch [5850/6000], Loss: 0.0043\n",
      "Epoch [5855/6000], Loss: 0.0043\n",
      "Epoch [5860/6000], Loss: 0.0043\n",
      "Epoch [5865/6000], Loss: 0.0043\n",
      "Epoch [5870/6000], Loss: 0.0043\n",
      "Epoch [5875/6000], Loss: 0.0043\n",
      "Epoch [5880/6000], Loss: 0.0043\n",
      "Epoch [5885/6000], Loss: 0.0043\n",
      "Epoch [5890/6000], Loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5895/6000], Loss: 0.0043\n",
      "Epoch [5900/6000], Loss: 0.0043\n",
      "Epoch [5905/6000], Loss: 0.0043\n",
      "Epoch [5910/6000], Loss: 0.0043\n",
      "Epoch [5915/6000], Loss: 0.0043\n",
      "Epoch [5920/6000], Loss: 0.0043\n",
      "Epoch [5925/6000], Loss: 0.0043\n",
      "Epoch [5930/6000], Loss: 0.0043\n",
      "Epoch [5935/6000], Loss: 0.0043\n",
      "Epoch [5940/6000], Loss: 0.0043\n",
      "Epoch [5945/6000], Loss: 0.0043\n",
      "Epoch [5950/6000], Loss: 0.0043\n",
      "Epoch [5955/6000], Loss: 0.0043\n",
      "Epoch [5960/6000], Loss: 0.0043\n",
      "Epoch [5965/6000], Loss: 0.0043\n",
      "Epoch [5970/6000], Loss: 0.0043\n",
      "Epoch [5975/6000], Loss: 0.0043\n",
      "Epoch [5980/6000], Loss: 0.0043\n",
      "Epoch [5985/6000], Loss: 0.0043\n",
      "Epoch [5990/6000], Loss: 0.0043\n",
      "Epoch [5995/6000], Loss: 0.0043\n",
      "Epoch [6000/6000], Loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model_relu(inputs)\n",
    "    loss = criterion_relu(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer_relu.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_relu.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/6000], Loss: 882.1727\n",
      "Epoch [10/6000], Loss: 900.3207\n",
      "Epoch [15/6000], Loss: 642.1105\n",
      "Epoch [20/6000], Loss: 448.9021\n",
      "Epoch [25/6000], Loss: 251.0016\n",
      "Epoch [30/6000], Loss: 826.4456\n",
      "Epoch [35/6000], Loss: 463.3998\n",
      "Epoch [40/6000], Loss: 469.2414\n",
      "Epoch [45/6000], Loss: 494.2238\n",
      "Epoch [50/6000], Loss: 593.8183\n",
      "Epoch [55/6000], Loss: 498.1797\n",
      "Epoch [60/6000], Loss: 466.0916\n",
      "Epoch [65/6000], Loss: 310.3888\n",
      "Epoch [70/6000], Loss: 500.4261\n",
      "Epoch [75/6000], Loss: 526.5210\n",
      "Epoch [80/6000], Loss: 442.9781\n",
      "Epoch [85/6000], Loss: 360.5838\n",
      "Epoch [90/6000], Loss: 256.7705\n",
      "Epoch [95/6000], Loss: 229.0115\n",
      "Epoch [100/6000], Loss: 149.3824\n",
      "Epoch [105/6000], Loss: 177.8061\n",
      "Epoch [110/6000], Loss: 261.6620\n",
      "Epoch [115/6000], Loss: 275.9206\n",
      "Epoch [120/6000], Loss: 457.9068\n",
      "Epoch [125/6000], Loss: 322.9458\n",
      "Epoch [130/6000], Loss: 194.6757\n",
      "Epoch [135/6000], Loss: 407.1833\n",
      "Epoch [140/6000], Loss: 378.0855\n",
      "Epoch [145/6000], Loss: 337.1260\n",
      "Epoch [150/6000], Loss: 418.2715\n",
      "Epoch [155/6000], Loss: 771.1859\n",
      "Epoch [160/6000], Loss: 653.8690\n",
      "Epoch [165/6000], Loss: 411.9884\n",
      "Epoch [170/6000], Loss: 460.0264\n",
      "Epoch [175/6000], Loss: 1016.4883\n",
      "Epoch [180/6000], Loss: 1087.5302\n",
      "Epoch [185/6000], Loss: 372.4360\n",
      "Epoch [190/6000], Loss: 474.9771\n",
      "Epoch [195/6000], Loss: 288.5070\n",
      "Epoch [200/6000], Loss: 278.0054\n",
      "Epoch [205/6000], Loss: 192.5841\n",
      "Epoch [210/6000], Loss: 491.4011\n",
      "Epoch [215/6000], Loss: 365.6355\n",
      "Epoch [220/6000], Loss: 325.5310\n",
      "Epoch [225/6000], Loss: 289.9083\n",
      "Epoch [230/6000], Loss: 713.6745\n",
      "Epoch [235/6000], Loss: 1135.0149\n",
      "Epoch [240/6000], Loss: 793.3190\n",
      "Epoch [245/6000], Loss: 487.3237\n",
      "Epoch [250/6000], Loss: 641.5145\n",
      "Epoch [255/6000], Loss: 461.8251\n",
      "Epoch [260/6000], Loss: 602.7457\n",
      "Epoch [265/6000], Loss: 441.9002\n",
      "Epoch [270/6000], Loss: 498.8279\n",
      "Epoch [275/6000], Loss: 459.1968\n",
      "Epoch [280/6000], Loss: 298.2688\n",
      "Epoch [285/6000], Loss: 383.5742\n",
      "Epoch [290/6000], Loss: 172.8211\n",
      "Epoch [295/6000], Loss: 176.9217\n",
      "Epoch [300/6000], Loss: 105.5945\n",
      "Epoch [305/6000], Loss: 62.6342\n",
      "Epoch [310/6000], Loss: 70.1160\n",
      "Epoch [315/6000], Loss: 60.1267\n",
      "Epoch [320/6000], Loss: 34.2338\n",
      "Epoch [325/6000], Loss: 28.6973\n",
      "Epoch [330/6000], Loss: 160.5832\n",
      "Epoch [335/6000], Loss: 295.3491\n",
      "Epoch [340/6000], Loss: 326.3555\n",
      "Epoch [345/6000], Loss: 138.7967\n",
      "Epoch [350/6000], Loss: 187.3749\n",
      "Epoch [355/6000], Loss: 596.4070\n",
      "Epoch [360/6000], Loss: 227.7242\n",
      "Epoch [365/6000], Loss: 236.4256\n",
      "Epoch [370/6000], Loss: 118.5115\n",
      "Epoch [375/6000], Loss: 116.6423\n",
      "Epoch [380/6000], Loss: 160.4428\n",
      "Epoch [385/6000], Loss: 174.7485\n",
      "Epoch [390/6000], Loss: 584.3646\n",
      "Epoch [395/6000], Loss: 1028.8915\n",
      "Epoch [400/6000], Loss: 1008.0540\n",
      "Epoch [405/6000], Loss: 945.3660\n",
      "Epoch [410/6000], Loss: 973.5101\n",
      "Epoch [415/6000], Loss: 941.5524\n",
      "Epoch [420/6000], Loss: 948.6176\n",
      "Epoch [425/6000], Loss: 942.1436\n",
      "Epoch [430/6000], Loss: 929.6988\n",
      "Epoch [435/6000], Loss: 974.0507\n",
      "Epoch [440/6000], Loss: 1011.0546\n",
      "Epoch [445/6000], Loss: 968.9960\n",
      "Epoch [450/6000], Loss: 948.5881\n",
      "Epoch [455/6000], Loss: 959.1533\n",
      "Epoch [460/6000], Loss: 940.9846\n",
      "Epoch [465/6000], Loss: 947.0446\n",
      "Epoch [470/6000], Loss: 942.1610\n",
      "Epoch [475/6000], Loss: 941.9777\n",
      "Epoch [480/6000], Loss: 942.0898\n",
      "Epoch [485/6000], Loss: 940.9915\n",
      "Epoch [490/6000], Loss: 941.4432\n",
      "Epoch [495/6000], Loss: 941.0034\n",
      "Epoch [500/6000], Loss: 941.0740\n",
      "Epoch [505/6000], Loss: 941.0278\n",
      "Epoch [510/6000], Loss: 940.9742\n",
      "Epoch [515/6000], Loss: 940.9997\n",
      "Epoch [520/6000], Loss: 940.9660\n",
      "Epoch [525/6000], Loss: 940.9750\n",
      "Epoch [530/6000], Loss: 940.9677\n",
      "Epoch [535/6000], Loss: 940.9658\n",
      "Epoch [540/6000], Loss: 940.9666\n",
      "Epoch [545/6000], Loss: 940.9641\n",
      "Epoch [550/6000], Loss: 940.9647\n",
      "Epoch [555/6000], Loss: 940.9637\n",
      "Epoch [560/6000], Loss: 940.9633\n",
      "Epoch [565/6000], Loss: 940.9632\n",
      "Epoch [570/6000], Loss: 940.9628\n",
      "Epoch [575/6000], Loss: 940.9625\n",
      "Epoch [580/6000], Loss: 940.9622\n",
      "Epoch [585/6000], Loss: 940.9618\n",
      "Epoch [590/6000], Loss: 940.9614\n",
      "Epoch [595/6000], Loss: 940.9613\n",
      "Epoch [600/6000], Loss: 940.9609\n",
      "Epoch [605/6000], Loss: 940.9606\n",
      "Epoch [610/6000], Loss: 940.9602\n",
      "Epoch [615/6000], Loss: 940.9599\n",
      "Epoch [620/6000], Loss: 940.9596\n",
      "Epoch [625/6000], Loss: 940.9594\n",
      "Epoch [630/6000], Loss: 940.9590\n",
      "Epoch [635/6000], Loss: 940.9586\n",
      "Epoch [640/6000], Loss: 940.9581\n",
      "Epoch [645/6000], Loss: 940.9578\n",
      "Epoch [650/6000], Loss: 940.9573\n",
      "Epoch [655/6000], Loss: 940.9570\n",
      "Epoch [660/6000], Loss: 940.9568\n",
      "Epoch [665/6000], Loss: 940.9561\n",
      "Epoch [670/6000], Loss: 940.9558\n",
      "Epoch [675/6000], Loss: 940.9553\n",
      "Epoch [680/6000], Loss: 940.9548\n",
      "Epoch [685/6000], Loss: 940.9547\n",
      "Epoch [690/6000], Loss: 940.9539\n",
      "Epoch [695/6000], Loss: 940.9534\n",
      "Epoch [700/6000], Loss: 940.9530\n",
      "Epoch [705/6000], Loss: 940.9525\n",
      "Epoch [710/6000], Loss: 940.9520\n",
      "Epoch [715/6000], Loss: 940.9515\n",
      "Epoch [720/6000], Loss: 940.9509\n",
      "Epoch [725/6000], Loss: 940.9504\n",
      "Epoch [730/6000], Loss: 940.9498\n",
      "Epoch [735/6000], Loss: 940.9493\n",
      "Epoch [740/6000], Loss: 940.9485\n",
      "Epoch [745/6000], Loss: 940.9479\n",
      "Epoch [750/6000], Loss: 940.9471\n",
      "Epoch [755/6000], Loss: 940.9468\n",
      "Epoch [760/6000], Loss: 940.9460\n",
      "Epoch [765/6000], Loss: 940.9450\n",
      "Epoch [770/6000], Loss: 940.9443\n",
      "Epoch [775/6000], Loss: 940.9435\n",
      "Epoch [780/6000], Loss: 940.9427\n",
      "Epoch [785/6000], Loss: 940.9417\n",
      "Epoch [790/6000], Loss: 940.9409\n",
      "Epoch [795/6000], Loss: 940.9397\n",
      "Epoch [800/6000], Loss: 940.9388\n",
      "Epoch [805/6000], Loss: 940.9377\n",
      "Epoch [810/6000], Loss: 940.9365\n",
      "Epoch [815/6000], Loss: 940.9354\n",
      "Epoch [820/6000], Loss: 940.9338\n",
      "Epoch [825/6000], Loss: 940.9326\n",
      "Epoch [830/6000], Loss: 940.9312\n",
      "Epoch [835/6000], Loss: 940.9297\n",
      "Epoch [840/6000], Loss: 940.9280\n",
      "Epoch [845/6000], Loss: 940.9260\n",
      "Epoch [850/6000], Loss: 940.9244\n",
      "Epoch [855/6000], Loss: 940.9222\n",
      "Epoch [860/6000], Loss: 940.9199\n",
      "Epoch [865/6000], Loss: 940.9176\n",
      "Epoch [870/6000], Loss: 940.9147\n",
      "Epoch [875/6000], Loss: 940.9120\n",
      "Epoch [880/6000], Loss: 940.9084\n",
      "Epoch [885/6000], Loss: 940.9052\n",
      "Epoch [890/6000], Loss: 940.9011\n",
      "Epoch [895/6000], Loss: 940.8964\n",
      "Epoch [900/6000], Loss: 940.8913\n",
      "Epoch [905/6000], Loss: 940.8853\n",
      "Epoch [910/6000], Loss: 940.8783\n",
      "Epoch [915/6000], Loss: 940.8702\n",
      "Epoch [920/6000], Loss: 940.8606\n",
      "Epoch [925/6000], Loss: 940.8489\n",
      "Epoch [930/6000], Loss: 940.8350\n",
      "Epoch [935/6000], Loss: 940.8170\n",
      "Epoch [940/6000], Loss: 940.7937\n",
      "Epoch [945/6000], Loss: 940.7626\n",
      "Epoch [950/6000], Loss: 940.7195\n",
      "Epoch [955/6000], Loss: 940.6553\n",
      "Epoch [960/6000], Loss: 940.5520\n",
      "Epoch [965/6000], Loss: 940.3644\n",
      "Epoch [970/6000], Loss: 939.9472\n",
      "Epoch [975/6000], Loss: 938.5667\n",
      "Epoch [980/6000], Loss: 923.1624\n",
      "Epoch [985/6000], Loss: 944.3052\n",
      "Epoch [990/6000], Loss: 942.0598\n",
      "Epoch [995/6000], Loss: 946.2198\n",
      "Epoch [1000/6000], Loss: 941.0568\n",
      "Epoch [1005/6000], Loss: 942.4558\n",
      "Epoch [1010/6000], Loss: 941.4345\n",
      "Epoch [1015/6000], Loss: 941.1474\n",
      "Epoch [1020/6000], Loss: 941.3022\n",
      "Epoch [1025/6000], Loss: 940.9553\n",
      "Epoch [1030/6000], Loss: 941.0801\n",
      "Epoch [1035/6000], Loss: 940.9730\n",
      "Epoch [1040/6000], Loss: 940.9773\n",
      "Epoch [1045/6000], Loss: 940.9740\n",
      "Epoch [1050/6000], Loss: 940.9541\n",
      "Epoch [1055/6000], Loss: 940.9623\n",
      "Epoch [1060/6000], Loss: 940.9526\n",
      "Epoch [1065/6000], Loss: 940.9541\n",
      "Epoch [1070/6000], Loss: 940.9524\n",
      "Epoch [1075/6000], Loss: 940.9510\n",
      "Epoch [1080/6000], Loss: 940.9509\n",
      "Epoch [1085/6000], Loss: 940.9498\n",
      "Epoch [1090/6000], Loss: 940.9495\n",
      "Epoch [1095/6000], Loss: 940.9487\n",
      "Epoch [1100/6000], Loss: 940.9482\n",
      "Epoch [1105/6000], Loss: 940.9476\n",
      "Epoch [1110/6000], Loss: 940.9470\n",
      "Epoch [1115/6000], Loss: 940.9465\n",
      "Epoch [1120/6000], Loss: 940.9457\n",
      "Epoch [1125/6000], Loss: 940.9451\n",
      "Epoch [1130/6000], Loss: 940.9445\n",
      "Epoch [1135/6000], Loss: 940.9438\n",
      "Epoch [1140/6000], Loss: 940.9432\n",
      "Epoch [1145/6000], Loss: 940.9423\n",
      "Epoch [1150/6000], Loss: 940.9415\n",
      "Epoch [1155/6000], Loss: 940.9409\n",
      "Epoch [1160/6000], Loss: 940.9401\n",
      "Epoch [1165/6000], Loss: 940.9393\n",
      "Epoch [1170/6000], Loss: 940.9384\n",
      "Epoch [1175/6000], Loss: 940.9373\n",
      "Epoch [1180/6000], Loss: 940.9365\n",
      "Epoch [1185/6000], Loss: 940.9355\n",
      "Epoch [1190/6000], Loss: 940.9344\n",
      "Epoch [1195/6000], Loss: 940.9335\n",
      "Epoch [1200/6000], Loss: 940.9322\n",
      "Epoch [1205/6000], Loss: 940.9310\n",
      "Epoch [1210/6000], Loss: 940.9299\n",
      "Epoch [1215/6000], Loss: 940.9286\n",
      "Epoch [1220/6000], Loss: 940.9274\n",
      "Epoch [1225/6000], Loss: 940.9258\n",
      "Epoch [1230/6000], Loss: 940.9245\n",
      "Epoch [1235/6000], Loss: 940.9227\n",
      "Epoch [1240/6000], Loss: 940.9211\n",
      "Epoch [1245/6000], Loss: 940.9192\n",
      "Epoch [1250/6000], Loss: 940.9174\n",
      "Epoch [1255/6000], Loss: 940.9155\n",
      "Epoch [1260/6000], Loss: 940.9132\n",
      "Epoch [1265/6000], Loss: 940.9110\n",
      "Epoch [1270/6000], Loss: 940.9086\n",
      "Epoch [1275/6000], Loss: 940.9059\n",
      "Epoch [1280/6000], Loss: 940.9033\n",
      "Epoch [1285/6000], Loss: 940.9002\n",
      "Epoch [1290/6000], Loss: 940.8969\n",
      "Epoch [1295/6000], Loss: 940.8934\n",
      "Epoch [1300/6000], Loss: 940.8895\n",
      "Epoch [1305/6000], Loss: 940.8855\n",
      "Epoch [1310/6000], Loss: 940.8809\n",
      "Epoch [1315/6000], Loss: 940.8754\n",
      "Epoch [1320/6000], Loss: 940.8701\n",
      "Epoch [1325/6000], Loss: 940.8636\n",
      "Epoch [1330/6000], Loss: 940.8563\n",
      "Epoch [1335/6000], Loss: 940.8485\n",
      "Epoch [1340/6000], Loss: 940.8391\n",
      "Epoch [1345/6000], Loss: 940.8286\n",
      "Epoch [1350/6000], Loss: 940.8162\n",
      "Epoch [1355/6000], Loss: 940.8012\n",
      "Epoch [1360/6000], Loss: 940.7838\n",
      "Epoch [1365/6000], Loss: 940.7623\n",
      "Epoch [1370/6000], Loss: 940.7356\n",
      "Epoch [1375/6000], Loss: 940.7012\n",
      "Epoch [1380/6000], Loss: 940.6553\n",
      "Epoch [1385/6000], Loss: 940.5911\n",
      "Epoch [1390/6000], Loss: 940.4946\n",
      "Epoch [1395/6000], Loss: 940.3332\n",
      "Epoch [1400/6000], Loss: 940.0073\n",
      "Epoch [1405/6000], Loss: 939.0345\n",
      "Epoch [1410/6000], Loss: 931.9286\n",
      "Epoch [1415/6000], Loss: 928.8489\n",
      "Epoch [1420/6000], Loss: 912.2441\n",
      "Epoch [1425/6000], Loss: 879.7515\n",
      "Epoch [1430/6000], Loss: 829.4548\n",
      "Epoch [1435/6000], Loss: 834.1303\n",
      "Epoch [1440/6000], Loss: 844.0012\n",
      "Epoch [1445/6000], Loss: 974.2467\n",
      "Epoch [1450/6000], Loss: 911.9438\n",
      "Epoch [1455/6000], Loss: 819.6383\n",
      "Epoch [1460/6000], Loss: 748.8653\n",
      "Epoch [1465/6000], Loss: 620.8771\n",
      "Epoch [1470/6000], Loss: 674.3641\n",
      "Epoch [1475/6000], Loss: 558.6497\n",
      "Epoch [1480/6000], Loss: 503.1138\n",
      "Epoch [1485/6000], Loss: 469.0098\n",
      "Epoch [1490/6000], Loss: 445.7184\n",
      "Epoch [1495/6000], Loss: 418.5227\n",
      "Epoch [1500/6000], Loss: 387.4073\n",
      "Epoch [1505/6000], Loss: 424.3729\n",
      "Epoch [1510/6000], Loss: 394.2220\n",
      "Epoch [1515/6000], Loss: 601.1790\n",
      "Epoch [1520/6000], Loss: 487.6078\n",
      "Epoch [1525/6000], Loss: 649.0496\n",
      "Epoch [1530/6000], Loss: 606.4930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1535/6000], Loss: 804.4079\n",
      "Epoch [1540/6000], Loss: 851.1396\n",
      "Epoch [1545/6000], Loss: 957.5515\n",
      "Epoch [1550/6000], Loss: 855.6536\n",
      "Epoch [1555/6000], Loss: 863.1636\n",
      "Epoch [1560/6000], Loss: 858.0603\n",
      "Epoch [1565/6000], Loss: 840.3984\n",
      "Epoch [1570/6000], Loss: 845.2626\n",
      "Epoch [1575/6000], Loss: 680.7344\n",
      "Epoch [1580/6000], Loss: 441.3002\n",
      "Epoch [1585/6000], Loss: 334.9769\n",
      "Epoch [1590/6000], Loss: 383.8013\n",
      "Epoch [1595/6000], Loss: 291.9999\n",
      "Epoch [1600/6000], Loss: 360.6461\n",
      "Epoch [1605/6000], Loss: 367.2280\n",
      "Epoch [1610/6000], Loss: 368.9852\n",
      "Epoch [1615/6000], Loss: 365.0084\n",
      "Epoch [1620/6000], Loss: 365.2466\n",
      "Epoch [1625/6000], Loss: 363.7563\n",
      "Epoch [1630/6000], Loss: 363.8965\n",
      "Epoch [1635/6000], Loss: 363.2503\n",
      "Epoch [1640/6000], Loss: 363.2953\n",
      "Epoch [1645/6000], Loss: 362.9485\n",
      "Epoch [1650/6000], Loss: 362.9028\n",
      "Epoch [1655/6000], Loss: 362.7324\n",
      "Epoch [1660/6000], Loss: 362.6499\n",
      "Epoch [1665/6000], Loss: 362.5395\n",
      "Epoch [1670/6000], Loss: 362.4474\n",
      "Epoch [1675/6000], Loss: 362.3517\n",
      "Epoch [1680/6000], Loss: 362.2589\n",
      "Epoch [1685/6000], Loss: 362.1665\n",
      "Epoch [1690/6000], Loss: 362.0726\n",
      "Epoch [1695/6000], Loss: 361.9784\n",
      "Epoch [1700/6000], Loss: 361.8820\n",
      "Epoch [1705/6000], Loss: 361.7840\n",
      "Epoch [1710/6000], Loss: 361.6836\n",
      "Epoch [1715/6000], Loss: 361.5806\n",
      "Epoch [1720/6000], Loss: 361.4747\n",
      "Epoch [1725/6000], Loss: 361.3656\n",
      "Epoch [1730/6000], Loss: 361.2528\n",
      "Epoch [1735/6000], Loss: 361.1363\n",
      "Epoch [1740/6000], Loss: 361.0153\n",
      "Epoch [1745/6000], Loss: 360.8898\n",
      "Epoch [1750/6000], Loss: 360.7590\n",
      "Epoch [1755/6000], Loss: 360.6226\n",
      "Epoch [1760/6000], Loss: 360.4801\n",
      "Epoch [1765/6000], Loss: 360.3305\n",
      "Epoch [1770/6000], Loss: 360.1732\n",
      "Epoch [1775/6000], Loss: 360.0071\n",
      "Epoch [1780/6000], Loss: 359.8307\n",
      "Epoch [1785/6000], Loss: 359.6426\n",
      "Epoch [1790/6000], Loss: 359.4400\n",
      "Epoch [1795/6000], Loss: 359.2186\n",
      "Epoch [1800/6000], Loss: 358.9681\n",
      "Epoch [1805/6000], Loss: 358.5807\n",
      "Epoch [1810/6000], Loss: 335.3176\n",
      "Epoch [1815/6000], Loss: 749.0753\n",
      "Epoch [1820/6000], Loss: 852.7690\n",
      "Epoch [1825/6000], Loss: 1169.2084\n",
      "Epoch [1830/6000], Loss: 842.9308\n",
      "Epoch [1835/6000], Loss: 922.2614\n",
      "Epoch [1840/6000], Loss: 831.8220\n",
      "Epoch [1845/6000], Loss: 684.8083\n",
      "Epoch [1850/6000], Loss: 346.5405\n",
      "Epoch [1855/6000], Loss: 500.7807\n",
      "Epoch [1860/6000], Loss: 968.1119\n",
      "Epoch [1865/6000], Loss: 999.7047\n",
      "Epoch [1870/6000], Loss: 940.9526\n",
      "Epoch [1875/6000], Loss: 961.1229\n",
      "Epoch [1880/6000], Loss: 944.5609\n",
      "Epoch [1885/6000], Loss: 944.4349\n",
      "Epoch [1890/6000], Loss: 944.5282\n",
      "Epoch [1895/6000], Loss: 941.0471\n",
      "Epoch [1900/6000], Loss: 942.5075\n",
      "Epoch [1905/6000], Loss: 941.0480\n",
      "Epoch [1910/6000], Loss: 941.3067\n",
      "Epoch [1915/6000], Loss: 941.1354\n",
      "Epoch [1920/6000], Loss: 940.9704\n",
      "Epoch [1925/6000], Loss: 941.0498\n",
      "Epoch [1930/6000], Loss: 940.9394\n",
      "Epoch [1935/6000], Loss: 940.9706\n",
      "Epoch [1940/6000], Loss: 940.9453\n",
      "Epoch [1945/6000], Loss: 940.9403\n",
      "Epoch [1950/6000], Loss: 940.9417\n",
      "Epoch [1955/6000], Loss: 940.9335\n",
      "Epoch [1960/6000], Loss: 940.9352\n",
      "Epoch [1965/6000], Loss: 940.9318\n",
      "Epoch [1970/6000], Loss: 940.9304\n",
      "Epoch [1975/6000], Loss: 940.9293\n",
      "Epoch [1980/6000], Loss: 940.9275\n",
      "Epoch [1985/6000], Loss: 940.9260\n",
      "Epoch [1990/6000], Loss: 940.9242\n",
      "Epoch [1995/6000], Loss: 940.9224\n",
      "Epoch [2000/6000], Loss: 940.9207\n",
      "Epoch [2005/6000], Loss: 940.9186\n",
      "Epoch [2010/6000], Loss: 940.9164\n",
      "Epoch [2015/6000], Loss: 940.9137\n",
      "Epoch [2020/6000], Loss: 940.9111\n",
      "Epoch [2025/6000], Loss: 940.9084\n",
      "Epoch [2030/6000], Loss: 940.9050\n",
      "Epoch [2035/6000], Loss: 940.9014\n",
      "Epoch [2040/6000], Loss: 940.8975\n",
      "Epoch [2045/6000], Loss: 940.8927\n",
      "Epoch [2050/6000], Loss: 940.8875\n",
      "Epoch [2055/6000], Loss: 940.8815\n",
      "Epoch [2060/6000], Loss: 940.8746\n",
      "Epoch [2065/6000], Loss: 940.8663\n",
      "Epoch [2070/6000], Loss: 940.8566\n",
      "Epoch [2075/6000], Loss: 940.8447\n",
      "Epoch [2080/6000], Loss: 940.8303\n",
      "Epoch [2085/6000], Loss: 940.8120\n",
      "Epoch [2090/6000], Loss: 940.7890\n",
      "Epoch [2095/6000], Loss: 940.7579\n",
      "Epoch [2100/6000], Loss: 940.7145\n",
      "Epoch [2105/6000], Loss: 940.6516\n",
      "Epoch [2110/6000], Loss: 940.5511\n",
      "Epoch [2115/6000], Loss: 940.3750\n",
      "Epoch [2120/6000], Loss: 940.0049\n",
      "Epoch [2125/6000], Loss: 938.9366\n",
      "Epoch [2130/6000], Loss: 932.4150\n",
      "Epoch [2135/6000], Loss: 794.3123\n",
      "Epoch [2140/6000], Loss: 766.3969\n",
      "Epoch [2145/6000], Loss: 943.5470\n",
      "Epoch [2150/6000], Loss: 955.1887\n",
      "Epoch [2155/6000], Loss: 941.3181\n",
      "Epoch [2160/6000], Loss: 944.8666\n",
      "Epoch [2165/6000], Loss: 942.3278\n",
      "Epoch [2170/6000], Loss: 941.4202\n",
      "Epoch [2175/6000], Loss: 941.9016\n",
      "Epoch [2180/6000], Loss: 940.9510\n",
      "Epoch [2185/6000], Loss: 941.2832\n",
      "Epoch [2190/6000], Loss: 941.0066\n",
      "Epoch [2195/6000], Loss: 941.0093\n",
      "Epoch [2200/6000], Loss: 941.0076\n",
      "Epoch [2205/6000], Loss: 940.9520\n",
      "Epoch [2210/6000], Loss: 940.9752\n",
      "Epoch [2215/6000], Loss: 940.9509\n",
      "Epoch [2220/6000], Loss: 940.9551\n",
      "Epoch [2225/6000], Loss: 940.9518\n",
      "Epoch [2230/6000], Loss: 940.9491\n",
      "Epoch [2235/6000], Loss: 940.9501\n",
      "Epoch [2240/6000], Loss: 940.9481\n",
      "Epoch [2245/6000], Loss: 940.9484\n",
      "Epoch [2250/6000], Loss: 940.9474\n",
      "Epoch [2255/6000], Loss: 940.9473\n",
      "Epoch [2260/6000], Loss: 940.9470\n",
      "Epoch [2265/6000], Loss: 940.9465\n",
      "Epoch [2270/6000], Loss: 940.9463\n",
      "Epoch [2275/6000], Loss: 940.9459\n",
      "Epoch [2280/6000], Loss: 940.9457\n",
      "Epoch [2285/6000], Loss: 940.9454\n",
      "Epoch [2290/6000], Loss: 940.9452\n",
      "Epoch [2295/6000], Loss: 940.9446\n",
      "Epoch [2300/6000], Loss: 940.9443\n",
      "Epoch [2305/6000], Loss: 940.9440\n",
      "Epoch [2310/6000], Loss: 940.9436\n",
      "Epoch [2315/6000], Loss: 940.9431\n",
      "Epoch [2320/6000], Loss: 940.9432\n",
      "Epoch [2325/6000], Loss: 940.9426\n",
      "Epoch [2330/6000], Loss: 940.9421\n",
      "Epoch [2335/6000], Loss: 940.9418\n",
      "Epoch [2340/6000], Loss: 940.9415\n",
      "Epoch [2345/6000], Loss: 940.9410\n",
      "Epoch [2350/6000], Loss: 940.9405\n",
      "Epoch [2355/6000], Loss: 940.9401\n",
      "Epoch [2360/6000], Loss: 940.9398\n",
      "Epoch [2365/6000], Loss: 940.9393\n",
      "Epoch [2370/6000], Loss: 940.9386\n",
      "Epoch [2375/6000], Loss: 940.9385\n",
      "Epoch [2380/6000], Loss: 940.9377\n",
      "Epoch [2385/6000], Loss: 940.9374\n",
      "Epoch [2390/6000], Loss: 940.9368\n",
      "Epoch [2395/6000], Loss: 940.9363\n",
      "Epoch [2400/6000], Loss: 940.9361\n",
      "Epoch [2405/6000], Loss: 940.9354\n",
      "Epoch [2410/6000], Loss: 940.9346\n",
      "Epoch [2415/6000], Loss: 940.9344\n",
      "Epoch [2420/6000], Loss: 940.9335\n",
      "Epoch [2425/6000], Loss: 940.9329\n",
      "Epoch [2430/6000], Loss: 940.9323\n",
      "Epoch [2435/6000], Loss: 940.9315\n",
      "Epoch [2440/6000], Loss: 940.9310\n",
      "Epoch [2445/6000], Loss: 940.9305\n",
      "Epoch [2450/6000], Loss: 940.9297\n",
      "Epoch [2455/6000], Loss: 940.9291\n",
      "Epoch [2460/6000], Loss: 940.9283\n",
      "Epoch [2465/6000], Loss: 940.9273\n",
      "Epoch [2470/6000], Loss: 940.9266\n",
      "Epoch [2475/6000], Loss: 940.9259\n",
      "Epoch [2480/6000], Loss: 940.9249\n",
      "Epoch [2485/6000], Loss: 940.9238\n",
      "Epoch [2490/6000], Loss: 940.9232\n",
      "Epoch [2495/6000], Loss: 940.9222\n",
      "Epoch [2500/6000], Loss: 940.9210\n",
      "Epoch [2505/6000], Loss: 940.9198\n",
      "Epoch [2510/6000], Loss: 940.9188\n",
      "Epoch [2515/6000], Loss: 940.9179\n",
      "Epoch [2520/6000], Loss: 940.9163\n",
      "Epoch [2525/6000], Loss: 940.9152\n",
      "Epoch [2530/6000], Loss: 940.9139\n",
      "Epoch [2535/6000], Loss: 940.9125\n",
      "Epoch [2540/6000], Loss: 940.9111\n",
      "Epoch [2545/6000], Loss: 940.9096\n",
      "Epoch [2550/6000], Loss: 940.9078\n",
      "Epoch [2555/6000], Loss: 940.9059\n",
      "Epoch [2560/6000], Loss: 940.9042\n",
      "Epoch [2565/6000], Loss: 940.9019\n",
      "Epoch [2570/6000], Loss: 940.8998\n",
      "Epoch [2575/6000], Loss: 940.8977\n",
      "Epoch [2580/6000], Loss: 940.8952\n",
      "Epoch [2585/6000], Loss: 940.8923\n",
      "Epoch [2590/6000], Loss: 940.8893\n",
      "Epoch [2595/6000], Loss: 940.8866\n",
      "Epoch [2600/6000], Loss: 940.8828\n",
      "Epoch [2605/6000], Loss: 940.8790\n",
      "Epoch [2610/6000], Loss: 940.8748\n",
      "Epoch [2615/6000], Loss: 940.8703\n",
      "Epoch [2620/6000], Loss: 940.8649\n",
      "Epoch [2625/6000], Loss: 940.8589\n",
      "Epoch [2630/6000], Loss: 940.8522\n",
      "Epoch [2635/6000], Loss: 940.8443\n",
      "Epoch [2640/6000], Loss: 940.8350\n",
      "Epoch [2645/6000], Loss: 940.8243\n",
      "Epoch [2650/6000], Loss: 940.8111\n",
      "Epoch [2655/6000], Loss: 940.7957\n",
      "Epoch [2660/6000], Loss: 940.7755\n",
      "Epoch [2665/6000], Loss: 940.7493\n",
      "Epoch [2670/6000], Loss: 940.7151\n",
      "Epoch [2675/6000], Loss: 940.6666\n",
      "Epoch [2680/6000], Loss: 940.5945\n",
      "Epoch [2685/6000], Loss: 940.4772\n",
      "Epoch [2690/6000], Loss: 940.2587\n",
      "Epoch [2695/6000], Loss: 939.7540\n",
      "Epoch [2700/6000], Loss: 937.9327\n",
      "Epoch [2705/6000], Loss: 911.0222\n",
      "Epoch [2710/6000], Loss: 956.1166\n",
      "Epoch [2715/6000], Loss: 941.0340\n",
      "Epoch [2720/6000], Loss: 946.9020\n",
      "Epoch [2725/6000], Loss: 941.5464\n",
      "Epoch [2730/6000], Loss: 942.1459\n",
      "Epoch [2735/6000], Loss: 941.7697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2740/6000], Loss: 940.9706\n",
      "Epoch [2745/6000], Loss: 941.3326\n",
      "Epoch [2750/6000], Loss: 940.9001\n",
      "Epoch [2755/6000], Loss: 941.0027\n",
      "Epoch [2760/6000], Loss: 940.9211\n",
      "Epoch [2765/6000], Loss: 940.8852\n",
      "Epoch [2770/6000], Loss: 940.8935\n",
      "Epoch [2775/6000], Loss: 940.8553\n",
      "Epoch [2780/6000], Loss: 940.8549\n",
      "Epoch [2785/6000], Loss: 940.8334\n",
      "Epoch [2790/6000], Loss: 940.8167\n",
      "Epoch [2795/6000], Loss: 940.7950\n",
      "Epoch [2800/6000], Loss: 940.7640\n",
      "Epoch [2805/6000], Loss: 940.7224\n",
      "Epoch [2810/6000], Loss: 940.6561\n",
      "Epoch [2815/6000], Loss: 940.5443\n",
      "Epoch [2820/6000], Loss: 940.3155\n",
      "Epoch [2825/6000], Loss: 939.6697\n",
      "Epoch [2830/6000], Loss: 935.4386\n",
      "Epoch [2835/6000], Loss: 930.2723\n",
      "Epoch [2840/6000], Loss: 916.8900\n",
      "Epoch [2845/6000], Loss: 918.3742\n",
      "Epoch [2850/6000], Loss: 928.0555\n",
      "Epoch [2855/6000], Loss: 937.5860\n",
      "Epoch [2860/6000], Loss: 936.1902\n",
      "Epoch [2865/6000], Loss: 897.5764\n",
      "Epoch [2870/6000], Loss: 798.2242\n",
      "Epoch [2875/6000], Loss: 748.6177\n",
      "Epoch [2880/6000], Loss: 702.2926\n",
      "Epoch [2885/6000], Loss: 631.8235\n",
      "Epoch [2890/6000], Loss: 595.1483\n",
      "Epoch [2895/6000], Loss: 538.3312\n",
      "Epoch [2900/6000], Loss: 551.0364\n",
      "Epoch [2905/6000], Loss: 489.0783\n",
      "Epoch [2910/6000], Loss: 478.3474\n",
      "Epoch [2915/6000], Loss: 455.0165\n",
      "Epoch [2920/6000], Loss: 417.2479\n",
      "Epoch [2925/6000], Loss: 398.6479\n",
      "Epoch [2930/6000], Loss: 383.3474\n",
      "Epoch [2935/6000], Loss: 433.3333\n",
      "Epoch [2940/6000], Loss: 313.1034\n",
      "Epoch [2945/6000], Loss: 363.3659\n",
      "Epoch [2950/6000], Loss: 282.7873\n",
      "Epoch [2955/6000], Loss: 331.6409\n",
      "Epoch [2960/6000], Loss: 296.2286\n",
      "Epoch [2965/6000], Loss: 428.1315\n",
      "Epoch [2970/6000], Loss: 348.4012\n",
      "Epoch [2975/6000], Loss: 502.2871\n",
      "Epoch [2980/6000], Loss: 270.9831\n",
      "Epoch [2985/6000], Loss: 465.6206\n",
      "Epoch [2990/6000], Loss: 958.0873\n",
      "Epoch [2995/6000], Loss: 766.3524\n",
      "Epoch [3000/6000], Loss: 922.3370\n",
      "Epoch [3005/6000], Loss: 524.9929\n",
      "Epoch [3010/6000], Loss: 712.3746\n",
      "Epoch [3015/6000], Loss: 617.5956\n",
      "Epoch [3020/6000], Loss: 463.7900\n",
      "Epoch [3025/6000], Loss: 492.8336\n",
      "Epoch [3030/6000], Loss: 333.0632\n",
      "Epoch [3035/6000], Loss: 297.3877\n",
      "Epoch [3040/6000], Loss: 382.5331\n",
      "Epoch [3045/6000], Loss: 346.4203\n",
      "Epoch [3050/6000], Loss: 297.3417\n",
      "Epoch [3055/6000], Loss: 291.5841\n",
      "Epoch [3060/6000], Loss: 284.5683\n",
      "Epoch [3065/6000], Loss: 278.4254\n",
      "Epoch [3070/6000], Loss: 276.0605\n",
      "Epoch [3075/6000], Loss: 271.5912\n",
      "Epoch [3080/6000], Loss: 266.0136\n",
      "Epoch [3085/6000], Loss: 262.4390\n",
      "Epoch [3090/6000], Loss: 258.9747\n",
      "Epoch [3095/6000], Loss: 255.6264\n",
      "Epoch [3100/6000], Loss: 252.4466\n",
      "Epoch [3105/6000], Loss: 249.5571\n",
      "Epoch [3110/6000], Loss: 246.8999\n",
      "Epoch [3115/6000], Loss: 244.4648\n",
      "Epoch [3120/6000], Loss: 242.1537\n",
      "Epoch [3125/6000], Loss: 239.9683\n",
      "Epoch [3130/6000], Loss: 237.8687\n",
      "Epoch [3135/6000], Loss: 235.8671\n",
      "Epoch [3140/6000], Loss: 233.9437\n",
      "Epoch [3145/6000], Loss: 232.0901\n",
      "Epoch [3150/6000], Loss: 230.3005\n",
      "Epoch [3155/6000], Loss: 228.5716\n",
      "Epoch [3160/6000], Loss: 226.9009\n",
      "Epoch [3165/6000], Loss: 225.3119\n",
      "Epoch [3170/6000], Loss: 245.0575\n",
      "Epoch [3175/6000], Loss: 306.4532\n",
      "Epoch [3180/6000], Loss: 1113.5072\n",
      "Epoch [3185/6000], Loss: 920.9183\n",
      "Epoch [3190/6000], Loss: 1455.6462\n",
      "Epoch [3195/6000], Loss: 1046.0726\n",
      "Epoch [3200/6000], Loss: 1024.2600\n",
      "Epoch [3205/6000], Loss: 1036.7759\n",
      "Epoch [3210/6000], Loss: 940.1638\n",
      "Epoch [3215/6000], Loss: 963.3174\n",
      "Epoch [3220/6000], Loss: 1102.7831\n",
      "Epoch [3225/6000], Loss: 955.0792\n",
      "Epoch [3230/6000], Loss: 976.5546\n",
      "Epoch [3235/6000], Loss: 962.8527\n",
      "Epoch [3240/6000], Loss: 943.4852\n",
      "Epoch [3245/6000], Loss: 952.6478\n",
      "Epoch [3250/6000], Loss: 941.1653\n",
      "Epoch [3255/6000], Loss: 944.2794\n",
      "Epoch [3260/6000], Loss: 942.0052\n",
      "Epoch [3265/6000], Loss: 941.3701\n",
      "Epoch [3270/6000], Loss: 941.7130\n",
      "Epoch [3275/6000], Loss: 940.9422\n",
      "Epoch [3280/6000], Loss: 941.2199\n",
      "Epoch [3285/6000], Loss: 940.9817\n",
      "Epoch [3290/6000], Loss: 940.9915\n",
      "Epoch [3295/6000], Loss: 940.9844\n",
      "Epoch [3300/6000], Loss: 940.9398\n",
      "Epoch [3305/6000], Loss: 940.9581\n",
      "Epoch [3310/6000], Loss: 940.9369\n",
      "Epoch [3315/6000], Loss: 940.9403\n",
      "Epoch [3320/6000], Loss: 940.9365\n",
      "Epoch [3325/6000], Loss: 940.9335\n",
      "Epoch [3330/6000], Loss: 940.9334\n",
      "Epoch [3335/6000], Loss: 940.9308\n",
      "Epoch [3340/6000], Loss: 940.9299\n",
      "Epoch [3345/6000], Loss: 940.9283\n",
      "Epoch [3350/6000], Loss: 940.9271\n",
      "Epoch [3355/6000], Loss: 940.9257\n",
      "Epoch [3360/6000], Loss: 940.9241\n",
      "Epoch [3365/6000], Loss: 940.9225\n",
      "Epoch [3370/6000], Loss: 940.9208\n",
      "Epoch [3375/6000], Loss: 940.9190\n",
      "Epoch [3380/6000], Loss: 940.9171\n",
      "Epoch [3385/6000], Loss: 940.9148\n",
      "Epoch [3390/6000], Loss: 940.9125\n",
      "Epoch [3395/6000], Loss: 940.9100\n",
      "Epoch [3400/6000], Loss: 940.9072\n",
      "Epoch [3405/6000], Loss: 940.9044\n",
      "Epoch [3410/6000], Loss: 940.9010\n",
      "Epoch [3415/6000], Loss: 940.8974\n",
      "Epoch [3420/6000], Loss: 940.8934\n",
      "Epoch [3425/6000], Loss: 940.8887\n",
      "Epoch [3430/6000], Loss: 940.8839\n",
      "Epoch [3435/6000], Loss: 940.8778\n",
      "Epoch [3440/6000], Loss: 940.8709\n",
      "Epoch [3445/6000], Loss: 940.8629\n",
      "Epoch [3450/6000], Loss: 940.8533\n",
      "Epoch [3455/6000], Loss: 940.8414\n",
      "Epoch [3460/6000], Loss: 940.8267\n",
      "Epoch [3465/6000], Loss: 940.8074\n",
      "Epoch [3470/6000], Loss: 940.7821\n",
      "Epoch [3475/6000], Loss: 940.7466\n",
      "Epoch [3480/6000], Loss: 940.6937\n",
      "Epoch [3485/6000], Loss: 940.6066\n",
      "Epoch [3490/6000], Loss: 940.4412\n",
      "Epoch [3495/6000], Loss: 940.0364\n",
      "Epoch [3500/6000], Loss: 938.3055\n",
      "Epoch [3505/6000], Loss: 933.7003\n",
      "Epoch [3510/6000], Loss: 928.7369\n",
      "Epoch [3515/6000], Loss: 916.0134\n",
      "Epoch [3520/6000], Loss: 890.5234\n",
      "Epoch [3525/6000], Loss: 844.6305\n",
      "Epoch [3530/6000], Loss: 848.6774\n",
      "Epoch [3535/6000], Loss: 789.0447\n",
      "Epoch [3540/6000], Loss: 736.2477\n",
      "Epoch [3545/6000], Loss: 660.9153\n",
      "Epoch [3550/6000], Loss: 641.1680\n",
      "Epoch [3555/6000], Loss: 563.9067\n",
      "Epoch [3560/6000], Loss: 619.0296\n",
      "Epoch [3565/6000], Loss: 492.4288\n",
      "Epoch [3570/6000], Loss: 505.7787\n",
      "Epoch [3575/6000], Loss: 409.9029\n",
      "Epoch [3580/6000], Loss: 632.0533\n",
      "Epoch [3585/6000], Loss: 368.0172\n",
      "Epoch [3590/6000], Loss: 393.4039\n",
      "Epoch [3595/6000], Loss: 357.6084\n",
      "Epoch [3600/6000], Loss: 444.4977\n",
      "Epoch [3605/6000], Loss: 359.5267\n",
      "Epoch [3610/6000], Loss: 353.7738\n",
      "Epoch [3615/6000], Loss: 491.5265\n",
      "Epoch [3620/6000], Loss: 522.2992\n",
      "Epoch [3625/6000], Loss: 378.2162\n",
      "Epoch [3630/6000], Loss: 376.0220\n",
      "Epoch [3635/6000], Loss: 290.1789\n",
      "Epoch [3640/6000], Loss: 420.0227\n",
      "Epoch [3645/6000], Loss: 318.6841\n",
      "Epoch [3650/6000], Loss: 400.7346\n",
      "Epoch [3655/6000], Loss: 471.6993\n",
      "Epoch [3660/6000], Loss: 402.4094\n",
      "Epoch [3665/6000], Loss: 385.9432\n",
      "Epoch [3670/6000], Loss: 288.8533\n",
      "Epoch [3675/6000], Loss: 348.0844\n",
      "Epoch [3680/6000], Loss: 339.7617\n",
      "Epoch [3685/6000], Loss: 703.4384\n",
      "Epoch [3690/6000], Loss: 579.5963\n",
      "Epoch [3695/6000], Loss: 508.7706\n",
      "Epoch [3700/6000], Loss: 361.0076\n",
      "Epoch [3705/6000], Loss: 296.7389\n",
      "Epoch [3710/6000], Loss: 361.6464\n",
      "Epoch [3715/6000], Loss: 562.1656\n",
      "Epoch [3720/6000], Loss: 295.5636\n",
      "Epoch [3725/6000], Loss: 299.8831\n",
      "Epoch [3730/6000], Loss: 287.3157\n",
      "Epoch [3735/6000], Loss: 712.6496\n",
      "Epoch [3740/6000], Loss: 539.3345\n",
      "Epoch [3745/6000], Loss: 548.9246\n",
      "Epoch [3750/6000], Loss: 520.2381\n",
      "Epoch [3755/6000], Loss: 485.4307\n",
      "Epoch [3760/6000], Loss: 372.4424\n",
      "Epoch [3765/6000], Loss: 264.9733\n",
      "Epoch [3770/6000], Loss: 458.3050\n",
      "Epoch [3775/6000], Loss: 287.3983\n",
      "Epoch [3780/6000], Loss: 287.4432\n",
      "Epoch [3785/6000], Loss: 302.4948\n",
      "Epoch [3790/6000], Loss: 429.6547\n",
      "Epoch [3795/6000], Loss: 271.0771\n",
      "Epoch [3800/6000], Loss: 535.6935\n",
      "Epoch [3805/6000], Loss: 479.7214\n",
      "Epoch [3810/6000], Loss: 828.9890\n",
      "Epoch [3815/6000], Loss: 666.4784\n",
      "Epoch [3820/6000], Loss: 719.2699\n",
      "Epoch [3825/6000], Loss: 664.1407\n",
      "Epoch [3830/6000], Loss: 673.9643\n",
      "Epoch [3835/6000], Loss: 661.4787\n",
      "Epoch [3840/6000], Loss: 499.6014\n",
      "Epoch [3845/6000], Loss: 266.1261\n",
      "Epoch [3850/6000], Loss: 387.6312\n",
      "Epoch [3855/6000], Loss: 379.4644\n",
      "Epoch [3860/6000], Loss: 298.2669\n",
      "Epoch [3865/6000], Loss: 380.3741\n",
      "Epoch [3870/6000], Loss: 395.3656\n",
      "Epoch [3875/6000], Loss: 280.1264\n",
      "Epoch [3880/6000], Loss: 296.0590\n",
      "Epoch [3885/6000], Loss: 508.0602\n",
      "Epoch [3890/6000], Loss: 605.7043\n",
      "Epoch [3895/6000], Loss: 335.2319\n",
      "Epoch [3900/6000], Loss: 508.3098\n",
      "Epoch [3905/6000], Loss: 515.7615\n",
      "Epoch [3910/6000], Loss: 496.5213\n",
      "Epoch [3915/6000], Loss: 502.8086\n",
      "Epoch [3920/6000], Loss: 496.1283\n",
      "Epoch [3925/6000], Loss: 495.0645\n",
      "Epoch [3930/6000], Loss: 492.6989\n",
      "Epoch [3935/6000], Loss: 491.7150\n",
      "Epoch [3940/6000], Loss: 491.2274\n",
      "Epoch [3945/6000], Loss: 490.1898\n",
      "Epoch [3950/6000], Loss: 489.9966\n",
      "Epoch [3955/6000], Loss: 489.4870\n",
      "Epoch [3960/6000], Loss: 489.2426\n",
      "Epoch [3965/6000], Loss: 488.9728\n",
      "Epoch [3970/6000], Loss: 488.7782\n",
      "Epoch [3975/6000], Loss: 488.6060\n",
      "Epoch [3980/6000], Loss: 488.4623\n",
      "Epoch [3985/6000], Loss: 488.3434\n",
      "Epoch [3990/6000], Loss: 488.2386\n",
      "Epoch [3995/6000], Loss: 488.1522\n",
      "Epoch [4000/6000], Loss: 488.0748\n",
      "Epoch [4005/6000], Loss: 488.0092\n",
      "Epoch [4010/6000], Loss: 487.9502\n",
      "Epoch [4015/6000], Loss: 487.8982\n",
      "Epoch [4020/6000], Loss: 487.8507\n",
      "Epoch [4025/6000], Loss: 487.8071\n",
      "Epoch [4030/6000], Loss: 487.7659\n",
      "Epoch [4035/6000], Loss: 487.7264\n",
      "Epoch [4040/6000], Loss: 487.6875\n",
      "Epoch [4045/6000], Loss: 487.6482\n",
      "Epoch [4050/6000], Loss: 487.6075\n",
      "Epoch [4055/6000], Loss: 487.5643\n",
      "Epoch [4060/6000], Loss: 487.5173\n",
      "Epoch [4065/6000], Loss: 487.4651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4070/6000], Loss: 487.4057\n",
      "Epoch [4075/6000], Loss: 487.3365\n",
      "Epoch [4080/6000], Loss: 487.2544\n",
      "Epoch [4085/6000], Loss: 487.1547\n",
      "Epoch [4090/6000], Loss: 487.0304\n",
      "Epoch [4095/6000], Loss: 486.8719\n",
      "Epoch [4100/6000], Loss: 486.6638\n",
      "Epoch [4105/6000], Loss: 486.3819\n",
      "Epoch [4110/6000], Loss: 485.9859\n",
      "Epoch [4115/6000], Loss: 485.4069\n",
      "Epoch [4120/6000], Loss: 484.5233\n",
      "Epoch [4125/6000], Loss: 483.1193\n",
      "Epoch [4130/6000], Loss: 480.8304\n",
      "Epoch [4135/6000], Loss: 477.1183\n",
      "Epoch [4140/6000], Loss: 471.3649\n",
      "Epoch [4145/6000], Loss: 463.0577\n",
      "Epoch [4150/6000], Loss: 451.9056\n",
      "Epoch [4155/6000], Loss: 437.9040\n",
      "Epoch [4160/6000], Loss: 421.3874\n",
      "Epoch [4165/6000], Loss: 453.8654\n",
      "Epoch [4170/6000], Loss: 492.5136\n",
      "Epoch [4175/6000], Loss: 491.3286\n",
      "Epoch [4180/6000], Loss: 488.7310\n",
      "Epoch [4185/6000], Loss: 489.6469\n",
      "Epoch [4190/6000], Loss: 488.0912\n",
      "Epoch [4195/6000], Loss: 488.6615\n",
      "Epoch [4200/6000], Loss: 488.0465\n",
      "Epoch [4205/6000], Loss: 488.2187\n",
      "Epoch [4210/6000], Loss: 488.0365\n",
      "Epoch [4215/6000], Loss: 488.0510\n",
      "Epoch [4220/6000], Loss: 488.0136\n",
      "Epoch [4225/6000], Loss: 487.9927\n",
      "Epoch [4230/6000], Loss: 487.9887\n",
      "Epoch [4235/6000], Loss: 487.9715\n",
      "Epoch [4240/6000], Loss: 487.9704\n",
      "Epoch [4245/6000], Loss: 487.9608\n",
      "Epoch [4250/6000], Loss: 487.9587\n",
      "Epoch [4255/6000], Loss: 487.9538\n",
      "Epoch [4260/6000], Loss: 487.9512\n",
      "Epoch [4265/6000], Loss: 487.9484\n",
      "Epoch [4270/6000], Loss: 487.9462\n",
      "Epoch [4275/6000], Loss: 487.9443\n",
      "Epoch [4280/6000], Loss: 487.9427\n",
      "Epoch [4285/6000], Loss: 487.9414\n",
      "Epoch [4290/6000], Loss: 487.9400\n",
      "Epoch [4295/6000], Loss: 487.9388\n",
      "Epoch [4300/6000], Loss: 487.9379\n",
      "Epoch [4305/6000], Loss: 487.9370\n",
      "Epoch [4310/6000], Loss: 487.9362\n",
      "Epoch [4315/6000], Loss: 487.9354\n",
      "Epoch [4320/6000], Loss: 487.9346\n",
      "Epoch [4325/6000], Loss: 487.9341\n",
      "Epoch [4330/6000], Loss: 487.9335\n",
      "Epoch [4335/6000], Loss: 487.9328\n",
      "Epoch [4340/6000], Loss: 487.9323\n",
      "Epoch [4345/6000], Loss: 487.9318\n",
      "Epoch [4350/6000], Loss: 487.9313\n",
      "Epoch [4355/6000], Loss: 487.9308\n",
      "Epoch [4360/6000], Loss: 487.9303\n",
      "Epoch [4365/6000], Loss: 487.9298\n",
      "Epoch [4370/6000], Loss: 487.9293\n",
      "Epoch [4375/6000], Loss: 487.9290\n",
      "Epoch [4380/6000], Loss: 487.9286\n",
      "Epoch [4385/6000], Loss: 487.9280\n",
      "Epoch [4390/6000], Loss: 487.9276\n",
      "Epoch [4395/6000], Loss: 487.9272\n",
      "Epoch [4400/6000], Loss: 487.9267\n",
      "Epoch [4405/6000], Loss: 487.9264\n",
      "Epoch [4410/6000], Loss: 487.9259\n",
      "Epoch [4415/6000], Loss: 487.9256\n",
      "Epoch [4420/6000], Loss: 487.9251\n",
      "Epoch [4425/6000], Loss: 487.9247\n",
      "Epoch [4430/6000], Loss: 487.9243\n",
      "Epoch [4435/6000], Loss: 487.9239\n",
      "Epoch [4440/6000], Loss: 487.9234\n",
      "Epoch [4445/6000], Loss: 487.9230\n",
      "Epoch [4450/6000], Loss: 487.9227\n",
      "Epoch [4455/6000], Loss: 487.9222\n",
      "Epoch [4460/6000], Loss: 487.9218\n",
      "Epoch [4465/6000], Loss: 487.9214\n",
      "Epoch [4470/6000], Loss: 487.9211\n",
      "Epoch [4475/6000], Loss: 487.9206\n",
      "Epoch [4480/6000], Loss: 487.9201\n",
      "Epoch [4485/6000], Loss: 487.9197\n",
      "Epoch [4490/6000], Loss: 487.9193\n",
      "Epoch [4495/6000], Loss: 487.9189\n",
      "Epoch [4500/6000], Loss: 487.9185\n",
      "Epoch [4505/6000], Loss: 487.9181\n",
      "Epoch [4510/6000], Loss: 487.9176\n",
      "Epoch [4515/6000], Loss: 487.9172\n",
      "Epoch [4520/6000], Loss: 487.9168\n",
      "Epoch [4525/6000], Loss: 487.9165\n",
      "Epoch [4530/6000], Loss: 487.9160\n",
      "Epoch [4535/6000], Loss: 487.9156\n",
      "Epoch [4540/6000], Loss: 487.9152\n",
      "Epoch [4545/6000], Loss: 487.9147\n",
      "Epoch [4550/6000], Loss: 487.9143\n",
      "Epoch [4555/6000], Loss: 487.9139\n",
      "Epoch [4560/6000], Loss: 487.9135\n",
      "Epoch [4565/6000], Loss: 487.9130\n",
      "Epoch [4570/6000], Loss: 487.9126\n",
      "Epoch [4575/6000], Loss: 487.9122\n",
      "Epoch [4580/6000], Loss: 487.9117\n",
      "Epoch [4585/6000], Loss: 487.9113\n",
      "Epoch [4590/6000], Loss: 487.9110\n",
      "Epoch [4595/6000], Loss: 487.9105\n",
      "Epoch [4600/6000], Loss: 487.9101\n",
      "Epoch [4605/6000], Loss: 487.9096\n",
      "Epoch [4610/6000], Loss: 487.9093\n",
      "Epoch [4615/6000], Loss: 487.9089\n",
      "Epoch [4620/6000], Loss: 487.9084\n",
      "Epoch [4625/6000], Loss: 487.9079\n",
      "Epoch [4630/6000], Loss: 487.9076\n",
      "Epoch [4635/6000], Loss: 487.9071\n",
      "Epoch [4640/6000], Loss: 487.9066\n",
      "Epoch [4645/6000], Loss: 487.9063\n",
      "Epoch [4650/6000], Loss: 487.9057\n",
      "Epoch [4655/6000], Loss: 487.9054\n",
      "Epoch [4660/6000], Loss: 487.9050\n",
      "Epoch [4665/6000], Loss: 487.9045\n",
      "Epoch [4670/6000], Loss: 487.9042\n",
      "Epoch [4675/6000], Loss: 487.9036\n",
      "Epoch [4680/6000], Loss: 487.9033\n",
      "Epoch [4685/6000], Loss: 487.9029\n",
      "Epoch [4690/6000], Loss: 487.9023\n",
      "Epoch [4695/6000], Loss: 487.9019\n",
      "Epoch [4700/6000], Loss: 487.9015\n",
      "Epoch [4705/6000], Loss: 487.9010\n",
      "Epoch [4710/6000], Loss: 487.9005\n",
      "Epoch [4715/6000], Loss: 487.9002\n",
      "Epoch [4720/6000], Loss: 487.8996\n",
      "Epoch [4725/6000], Loss: 487.8993\n",
      "Epoch [4730/6000], Loss: 487.8989\n",
      "Epoch [4735/6000], Loss: 487.8983\n",
      "Epoch [4740/6000], Loss: 487.8979\n",
      "Epoch [4745/6000], Loss: 487.8976\n",
      "Epoch [4750/6000], Loss: 487.8971\n",
      "Epoch [4755/6000], Loss: 487.8965\n",
      "Epoch [4760/6000], Loss: 487.8962\n",
      "Epoch [4765/6000], Loss: 487.8957\n",
      "Epoch [4770/6000], Loss: 487.8952\n",
      "Epoch [4775/6000], Loss: 487.8949\n",
      "Epoch [4780/6000], Loss: 487.8943\n",
      "Epoch [4785/6000], Loss: 487.8940\n",
      "Epoch [4790/6000], Loss: 487.8935\n",
      "Epoch [4795/6000], Loss: 487.8931\n",
      "Epoch [4800/6000], Loss: 487.8925\n",
      "Epoch [4805/6000], Loss: 487.8921\n",
      "Epoch [4810/6000], Loss: 487.8916\n",
      "Epoch [4815/6000], Loss: 487.8912\n",
      "Epoch [4820/6000], Loss: 487.8908\n",
      "Epoch [4825/6000], Loss: 487.8903\n",
      "Epoch [4830/6000], Loss: 487.8900\n",
      "Epoch [4835/6000], Loss: 487.8894\n",
      "Epoch [4840/6000], Loss: 487.8890\n",
      "Epoch [4845/6000], Loss: 487.8885\n",
      "Epoch [4850/6000], Loss: 487.8880\n",
      "Epoch [4855/6000], Loss: 487.8877\n",
      "Epoch [4860/6000], Loss: 487.8871\n",
      "Epoch [4865/6000], Loss: 487.8867\n",
      "Epoch [4870/6000], Loss: 487.8863\n",
      "Epoch [4875/6000], Loss: 487.8859\n",
      "Epoch [4880/6000], Loss: 487.8853\n",
      "Epoch [4885/6000], Loss: 487.8848\n",
      "Epoch [4890/6000], Loss: 487.8843\n",
      "Epoch [4895/6000], Loss: 487.8839\n",
      "Epoch [4900/6000], Loss: 487.8835\n",
      "Epoch [4905/6000], Loss: 487.8830\n",
      "Epoch [4910/6000], Loss: 487.8825\n",
      "Epoch [4915/6000], Loss: 487.8820\n",
      "Epoch [4920/6000], Loss: 487.8816\n",
      "Epoch [4925/6000], Loss: 487.8812\n",
      "Epoch [4930/6000], Loss: 487.8807\n",
      "Epoch [4935/6000], Loss: 487.8803\n",
      "Epoch [4940/6000], Loss: 487.8798\n",
      "Epoch [4945/6000], Loss: 487.8792\n",
      "Epoch [4950/6000], Loss: 487.8788\n",
      "Epoch [4955/6000], Loss: 487.8783\n",
      "Epoch [4960/6000], Loss: 487.8779\n",
      "Epoch [4965/6000], Loss: 487.8774\n",
      "Epoch [4970/6000], Loss: 487.8770\n",
      "Epoch [4975/6000], Loss: 487.8764\n",
      "Epoch [4980/6000], Loss: 487.8760\n",
      "Epoch [4985/6000], Loss: 487.8755\n",
      "Epoch [4990/6000], Loss: 487.8750\n",
      "Epoch [4995/6000], Loss: 487.8746\n",
      "Epoch [5000/6000], Loss: 487.8741\n",
      "Epoch [5005/6000], Loss: 487.8737\n",
      "Epoch [5010/6000], Loss: 487.8731\n",
      "Epoch [5015/6000], Loss: 487.8727\n",
      "Epoch [5020/6000], Loss: 487.8722\n",
      "Epoch [5025/6000], Loss: 487.8718\n",
      "Epoch [5030/6000], Loss: 487.8713\n",
      "Epoch [5035/6000], Loss: 487.8707\n",
      "Epoch [5040/6000], Loss: 487.8702\n",
      "Epoch [5045/6000], Loss: 487.8698\n",
      "Epoch [5050/6000], Loss: 487.8694\n",
      "Epoch [5055/6000], Loss: 487.8687\n",
      "Epoch [5060/6000], Loss: 487.8683\n",
      "Epoch [5065/6000], Loss: 487.8679\n",
      "Epoch [5070/6000], Loss: 487.8672\n",
      "Epoch [5075/6000], Loss: 487.8669\n",
      "Epoch [5080/6000], Loss: 487.8664\n",
      "Epoch [5085/6000], Loss: 487.8658\n",
      "Epoch [5090/6000], Loss: 487.8654\n",
      "Epoch [5095/6000], Loss: 487.8649\n",
      "Epoch [5100/6000], Loss: 487.8643\n",
      "Epoch [5105/6000], Loss: 487.8639\n",
      "Epoch [5110/6000], Loss: 487.8634\n",
      "Epoch [5115/6000], Loss: 487.8630\n",
      "Epoch [5120/6000], Loss: 487.8625\n",
      "Epoch [5125/6000], Loss: 487.8619\n",
      "Epoch [5130/6000], Loss: 487.8616\n",
      "Epoch [5135/6000], Loss: 487.8610\n",
      "Epoch [5140/6000], Loss: 487.8605\n",
      "Epoch [5145/6000], Loss: 487.8600\n",
      "Epoch [5150/6000], Loss: 487.8596\n",
      "Epoch [5155/6000], Loss: 487.8589\n",
      "Epoch [5160/6000], Loss: 487.8585\n",
      "Epoch [5165/6000], Loss: 487.8580\n",
      "Epoch [5170/6000], Loss: 487.8575\n",
      "Epoch [5175/6000], Loss: 487.8571\n",
      "Epoch [5180/6000], Loss: 487.8565\n",
      "Epoch [5185/6000], Loss: 487.8559\n",
      "Epoch [5190/6000], Loss: 487.8555\n",
      "Epoch [5195/6000], Loss: 487.8550\n",
      "Epoch [5200/6000], Loss: 487.8544\n",
      "Epoch [5205/6000], Loss: 487.8540\n",
      "Epoch [5210/6000], Loss: 487.8535\n",
      "Epoch [5215/6000], Loss: 487.8529\n",
      "Epoch [5220/6000], Loss: 487.8525\n",
      "Epoch [5225/6000], Loss: 487.8520\n",
      "Epoch [5230/6000], Loss: 487.8514\n",
      "Epoch [5235/6000], Loss: 487.8509\n",
      "Epoch [5240/6000], Loss: 487.8504\n",
      "Epoch [5245/6000], Loss: 487.8499\n",
      "Epoch [5250/6000], Loss: 487.8494\n",
      "Epoch [5255/6000], Loss: 487.8489\n",
      "Epoch [5260/6000], Loss: 487.8484\n",
      "Epoch [5265/6000], Loss: 487.8479\n",
      "Epoch [5270/6000], Loss: 487.8473\n",
      "Epoch [5275/6000], Loss: 487.8468\n",
      "Epoch [5280/6000], Loss: 487.8463\n",
      "Epoch [5285/6000], Loss: 487.8458\n",
      "Epoch [5290/6000], Loss: 487.8453\n",
      "Epoch [5295/6000], Loss: 487.8447\n",
      "Epoch [5300/6000], Loss: 487.8442\n",
      "Epoch [5305/6000], Loss: 487.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5310/6000], Loss: 487.8432\n",
      "Epoch [5315/6000], Loss: 487.8427\n",
      "Epoch [5320/6000], Loss: 487.8421\n",
      "Epoch [5325/6000], Loss: 487.8416\n",
      "Epoch [5330/6000], Loss: 487.8411\n",
      "Epoch [5335/6000], Loss: 487.8405\n",
      "Epoch [5340/6000], Loss: 487.8400\n",
      "Epoch [5345/6000], Loss: 487.8395\n",
      "Epoch [5350/6000], Loss: 487.8390\n",
      "Epoch [5355/6000], Loss: 487.8383\n",
      "Epoch [5360/6000], Loss: 487.8379\n",
      "Epoch [5365/6000], Loss: 487.8375\n",
      "Epoch [5370/6000], Loss: 487.8369\n",
      "Epoch [5375/6000], Loss: 487.8362\n",
      "Epoch [5380/6000], Loss: 487.8357\n",
      "Epoch [5385/6000], Loss: 487.8351\n",
      "Epoch [5390/6000], Loss: 487.8348\n",
      "Epoch [5395/6000], Loss: 487.8341\n",
      "Epoch [5400/6000], Loss: 487.8336\n",
      "Epoch [5405/6000], Loss: 487.8331\n",
      "Epoch [5410/6000], Loss: 487.8326\n",
      "Epoch [5415/6000], Loss: 487.8320\n",
      "Epoch [5420/6000], Loss: 487.8314\n",
      "Epoch [5425/6000], Loss: 487.8309\n",
      "Epoch [5430/6000], Loss: 487.8304\n",
      "Epoch [5435/6000], Loss: 487.8298\n",
      "Epoch [5440/6000], Loss: 487.8293\n",
      "Epoch [5445/6000], Loss: 487.8288\n",
      "Epoch [5450/6000], Loss: 487.8283\n",
      "Epoch [5455/6000], Loss: 487.8276\n",
      "Epoch [5460/6000], Loss: 487.8272\n",
      "Epoch [5465/6000], Loss: 487.8266\n",
      "Epoch [5470/6000], Loss: 487.8261\n",
      "Epoch [5475/6000], Loss: 487.8255\n",
      "Epoch [5480/6000], Loss: 487.8249\n",
      "Epoch [5485/6000], Loss: 487.8244\n",
      "Epoch [5490/6000], Loss: 487.8238\n",
      "Epoch [5495/6000], Loss: 487.8233\n",
      "Epoch [5500/6000], Loss: 487.8227\n",
      "Epoch [5505/6000], Loss: 487.8223\n",
      "Epoch [5510/6000], Loss: 487.8216\n",
      "Epoch [5515/6000], Loss: 487.8210\n",
      "Epoch [5520/6000], Loss: 487.8204\n",
      "Epoch [5525/6000], Loss: 487.8200\n",
      "Epoch [5530/6000], Loss: 487.8194\n",
      "Epoch [5535/6000], Loss: 487.8189\n",
      "Epoch [5540/6000], Loss: 487.8182\n",
      "Epoch [5545/6000], Loss: 487.8177\n",
      "Epoch [5550/6000], Loss: 487.8171\n",
      "Epoch [5555/6000], Loss: 487.8165\n",
      "Epoch [5560/6000], Loss: 487.8161\n",
      "Epoch [5565/6000], Loss: 487.8155\n",
      "Epoch [5570/6000], Loss: 487.8148\n",
      "Epoch [5575/6000], Loss: 487.8143\n",
      "Epoch [5580/6000], Loss: 487.8137\n",
      "Epoch [5585/6000], Loss: 487.8132\n",
      "Epoch [5590/6000], Loss: 487.8127\n",
      "Epoch [5595/6000], Loss: 487.8120\n",
      "Epoch [5600/6000], Loss: 487.8114\n",
      "Epoch [5605/6000], Loss: 487.8108\n",
      "Epoch [5610/6000], Loss: 487.8103\n",
      "Epoch [5615/6000], Loss: 487.8097\n",
      "Epoch [5620/6000], Loss: 487.8091\n",
      "Epoch [5625/6000], Loss: 487.8085\n",
      "Epoch [5630/6000], Loss: 487.8080\n",
      "Epoch [5635/6000], Loss: 487.8074\n",
      "Epoch [5640/6000], Loss: 487.8068\n",
      "Epoch [5645/6000], Loss: 487.8062\n",
      "Epoch [5650/6000], Loss: 487.8056\n",
      "Epoch [5655/6000], Loss: 487.8051\n",
      "Epoch [5660/6000], Loss: 487.8044\n",
      "Epoch [5665/6000], Loss: 487.8039\n",
      "Epoch [5670/6000], Loss: 487.8033\n",
      "Epoch [5675/6000], Loss: 487.8027\n",
      "Epoch [5680/6000], Loss: 487.8020\n",
      "Epoch [5685/6000], Loss: 487.8015\n",
      "Epoch [5690/6000], Loss: 487.8009\n",
      "Epoch [5695/6000], Loss: 487.8004\n",
      "Epoch [5700/6000], Loss: 487.7998\n",
      "Epoch [5705/6000], Loss: 487.7992\n",
      "Epoch [5710/6000], Loss: 487.7985\n",
      "Epoch [5715/6000], Loss: 487.7979\n",
      "Epoch [5720/6000], Loss: 487.7974\n",
      "Epoch [5725/6000], Loss: 487.7968\n",
      "Epoch [5730/6000], Loss: 487.7962\n",
      "Epoch [5735/6000], Loss: 487.7956\n",
      "Epoch [5740/6000], Loss: 487.7950\n",
      "Epoch [5745/6000], Loss: 487.7943\n",
      "Epoch [5750/6000], Loss: 487.7937\n",
      "Epoch [5755/6000], Loss: 487.7932\n",
      "Epoch [5760/6000], Loss: 487.7926\n",
      "Epoch [5765/6000], Loss: 487.7920\n",
      "Epoch [5770/6000], Loss: 487.7914\n",
      "Epoch [5775/6000], Loss: 487.7907\n",
      "Epoch [5780/6000], Loss: 487.7902\n",
      "Epoch [5785/6000], Loss: 487.7896\n",
      "Epoch [5790/6000], Loss: 487.7889\n",
      "Epoch [5795/6000], Loss: 487.7883\n",
      "Epoch [5800/6000], Loss: 487.7877\n",
      "Epoch [5805/6000], Loss: 487.7870\n",
      "Epoch [5810/6000], Loss: 487.7865\n",
      "Epoch [5815/6000], Loss: 487.7858\n",
      "Epoch [5820/6000], Loss: 487.7852\n",
      "Epoch [5825/6000], Loss: 487.7845\n",
      "Epoch [5830/6000], Loss: 487.7840\n",
      "Epoch [5835/6000], Loss: 487.7834\n",
      "Epoch [5840/6000], Loss: 487.7827\n",
      "Epoch [5845/6000], Loss: 487.7821\n",
      "Epoch [5850/6000], Loss: 487.7814\n",
      "Epoch [5855/6000], Loss: 487.7809\n",
      "Epoch [5860/6000], Loss: 487.7802\n",
      "Epoch [5865/6000], Loss: 487.7796\n",
      "Epoch [5870/6000], Loss: 487.7789\n",
      "Epoch [5875/6000], Loss: 487.7783\n",
      "Epoch [5880/6000], Loss: 487.7775\n",
      "Epoch [5885/6000], Loss: 487.7771\n",
      "Epoch [5890/6000], Loss: 487.7764\n",
      "Epoch [5895/6000], Loss: 487.7758\n",
      "Epoch [5900/6000], Loss: 487.7751\n",
      "Epoch [5905/6000], Loss: 487.7745\n",
      "Epoch [5910/6000], Loss: 487.7739\n",
      "Epoch [5915/6000], Loss: 487.7733\n",
      "Epoch [5920/6000], Loss: 487.7725\n",
      "Epoch [5925/6000], Loss: 487.7720\n",
      "Epoch [5930/6000], Loss: 487.7712\n",
      "Epoch [5935/6000], Loss: 487.7706\n",
      "Epoch [5940/6000], Loss: 487.7701\n",
      "Epoch [5945/6000], Loss: 487.7694\n",
      "Epoch [5950/6000], Loss: 487.7686\n",
      "Epoch [5955/6000], Loss: 487.7680\n",
      "Epoch [5960/6000], Loss: 487.7675\n",
      "Epoch [5965/6000], Loss: 487.7667\n",
      "Epoch [5970/6000], Loss: 487.7661\n",
      "Epoch [5975/6000], Loss: 487.7655\n",
      "Epoch [5980/6000], Loss: 487.7649\n",
      "Epoch [5985/6000], Loss: 487.7641\n",
      "Epoch [5990/6000], Loss: 487.7635\n",
      "Epoch [5995/6000], Loss: 487.7629\n",
      "Epoch [6000/6000], Loss: 487.7621\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model_tanh(inputs)\n",
    "    loss = criterion_tanh(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer_tanh.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_tanh.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted_relu = model_relu(torch.from_numpy(x_train)).detach().numpy()\n",
    "predicted_tanh = model_tanh(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted_relu, 'bo', label='Fitted line, ReLu')\n",
    "plt.plot(x_train, predicted_tanh, 'go', label='Fitted line, Tanh')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss: 0.0043\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 6000\n",
    "momentum = 0.9\n",
    "hs = 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
